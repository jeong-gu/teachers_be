# -*- coding: utf-8 -*-
import os
import re
import uuid
import json
import time
import shutil
import datetime as dt
from pathlib import Path
from typing import Optional, List, Dict, Any, Tuple
from collections import defaultdict

from fastapi import FastAPI, UploadFile, File, Request
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import FileResponse, HTMLResponse
from fastapi.templating import Jinja2Templates

from pydantic import BaseModel, Field
from dotenv import load_dotenv, find_dotenv

from sqlalchemy import create_engine, Column, Integer, String, Text, DateTime
from sqlalchemy.orm import sessionmaker, declarative_base

# LangChain & Clova
from openai import RateLimitError
from langchain_naver import ChatClovaX, ClovaXEmbeddings
from langchain_community.document_loaders import PyPDFLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import FAISS
from langchain.prompts import ChatPromptTemplate
from langchain.chains import RetrievalQA
from langchain_core.embeddings import Embeddings

import requests

# =========================
# 0) ENV & PATHS
# =========================
load_dotenv(find_dotenv())

ROOT_DIR   = os.path.abspath(os.path.dirname(__file__))
DATA_DIR   = os.path.abspath(os.path.join(ROOT_DIR, "..", "data"))
UPLOAD_DIR = os.path.join(DATA_DIR, "uploads")
AUDIO_DIR  = os.path.join(DATA_DIR, "audio")
VECTOR_DIR = os.getenv("VECTOR_DIR", os.path.join(DATA_DIR, "faiss"))
SQLITE_PATH = os.getenv("SQLITE_PATH", os.path.join(DATA_DIR, "app.db"))

os.makedirs(UPLOAD_DIR, exist_ok=True)
os.makedirs(AUDIO_DIR, exist_ok=True)
os.makedirs(VECTOR_DIR, exist_ok=True)

# =========================
# 1) Persona & TTS Config
# =========================
PERSONAS: Dict[str, Dict[str, str]] = {
    "ngoeun": {
        "display": "ê³ ì€", "sex": "ì—¬ì„±", "speaker": "ngoeun",
        "persona_rules": (
            "ë‹¹ì‹ ì€ ì¹œì ˆí•˜ê³  ë”°ëœ»í•œ ì—¬ì ì„ ìƒë‹˜ì…ë‹ˆë‹¤. "
            "í•™ìƒì´ í¸ì•ˆí•˜ê²Œ ëŠë‚„ ìˆ˜ ìˆë„ë¡ ì°¨ë¶„í•˜ê³  ë¶€ë“œëŸ¬ìš´ ë§íˆ¬ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”. "
            "ì–´ë ¤ìš´ ê°œë…ì€ ê¸°ì´ˆë¶€í„° ì°¨ê·¼ì°¨ê·¼ ì„¤ëª…í•˜ê³ , ì´í•´ê°€ ì˜ ë˜ë„ë¡ ì˜ˆì‹œë¥¼ ë“¤ì–´ì£¼ì„¸ìš”. "
            "ë§ˆì§€ë§‰ì—ëŠ” â€œë„ˆë¬´ ì˜í–ˆì–´ìš”!â€, â€œì¡°ê¸ˆì”© ë‚˜ì•„ì§€ê³  ìˆì–´ìš”â€ ê°™ì€ ê²©ë ¤ ë©˜íŠ¸ë¥¼ ë°˜ë“œì‹œ í¬í•¨í•˜ì„¸ìš”."
        ),
    },
    "nkyuwon": {
        "display": "ê·œì›", "sex": "ë‚¨ì„±", "speaker": "nkyuwon",
        "persona_rules": (
            "ë‹¹ì‹ ì€ ê°™ì€ ë˜ë˜ ì¹œêµ¬ì²˜ëŸ¼ ì¹œê·¼í•˜ê³  í¸ì•ˆí•œ í†¤ìœ¼ë¡œ ê°€ë¥´ì³ì£¼ëŠ” ì—­í• ì…ë‹ˆë‹¤. "
            "ì „ë¬¸ì ì¸ ìš©ì–´ë¥¼ ì“°ê¸°ë³´ë‹¤ëŠ” ì¼ìƒì ì¸ ì–¸ì–´ì™€ ë¹„ìœ ë¥¼ í™œìš©í•´ ì„¤ëª…í•˜ì„¸ìš”. "
            "ì–´ë ¤ìš´ ê°œë…ì´ ë‚˜ì˜¤ë©´ â€œì´ê±°ëŠ” ë§ˆì¹˜ â—‹â—‹ ê°™ì€ ê±°ì•¼â€ ì‹ìœ¼ë¡œ ì‰½ê²Œ í’€ì–´ì£¼ì„¸ìš”. "
            "í•™ìƒì´ ë¶€ë‹´ì„ ëŠë¼ì§€ ì•Šë„ë¡ ê°€ë³ê³  ìºì£¼ì–¼í•œ ë¶„ìœ„ê¸°ë¥¼ ìœ ì§€í•˜ì„¸ìš”."
        ),
    },
    "nminjeong": {
        "display": "ë¯¼ì •", "sex": "ì—¬ì„±", "speaker": "nminjeong",
        "persona_rules": (
            "ë‹¹ì‹ ì€ ì¹´ë¦¬ìŠ¤ë§ˆ ìˆê³  ì„íŒ©íŠ¸ ìˆëŠ” ì¼íƒ€ê°•ì‚¬ ìŠ¤íƒ€ì¼ì˜ ê°•ì‚¬ì…ë‹ˆë‹¤. "
            "ë¹ ë¥¸ í…œí¬ì™€ ê°•í•œ ìì‹ ê°ìœ¼ë¡œ í•µì‹¬ë§Œ ì½• ì§‘ì–´ ì„¤ëª…í•˜ì„¸ìš”. "
            "ë¶ˆí•„ìš”í•œ ë§ì€ ì¤„ì´ê³ , â€œì´ ë¶€ë¶„ì€ ë¬´ì¡°ê±´ ì™¸ì›Œì•¼ í•œë‹¤â€, â€œì´ê±° ì‹œí—˜ì— 100% ë‚˜ì˜¨ë‹¤â€ ê°™ì€ ê°•ì¡° ë©˜íŠ¸ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”. "
            "ê°€ë”ì€ í•™ìƒì„ ê¸´ì¥ì‹œí‚¤ë©´ì„œë„ ë™ê¸°ë¶€ì—¬ê°€ ë  ìˆ˜ ìˆë„ë¡ â€œì´ê±¸ ëª¨ë¥´ë©´ í°ì¼ ë‚©ë‹ˆë‹¤â€ ê°™ì€ ë©˜íŠ¸ë¥¼ ë„£ìœ¼ì„¸ìš”."
        ),
    },
    "nheera": {
        "display": "í¬ë¼", "sex": "ì—¬ì„±", "speaker": "nheera",
        "persona_rules": (
            "ë‹¹ì‹ ì€ ì°¨ë¶„í•˜ê³  ë…¼ë¦¬ì ì¸ ë¶„ì„í˜• íŠœí„°ì…ë‹ˆë‹¤. "
            "í•™ìƒì´ ìŠ¤ìŠ¤ë¡œ ì‚¬ê³ í•  ìˆ˜ ìˆë„ë¡ ì§ˆë¬¸ì„ ë˜ì§€ë©° ì„¤ëª…ì„ ì´ëŒì–´ê°€ì„¸ìš”. "
            "ì„¤ëª…ì€ 'í•µì‹¬ ìš”ì•½ â†’ ë‹¨ê³„ì  ë¶„ì„ â†’ ê´€ë ¨ ì§ˆë¬¸ â†’ ì •ë‹µ ë° í•´ì„¤' ìˆœì„œë¡œ ì§„í–‰í•©ë‹ˆë‹¤. "
            "ë³µì¡í•œ ê°œë…ì€ ë„ì‹ì Â·ë‹¨ê³„ì  ì–¸ì–´ë¡œ ë¶„í•´í•´ ì£¼ë©°, ë§ˆì§€ë§‰ì—ëŠ” â€œì´ì œ ë‹¹ì‹  ì°¨ë¡€ì˜ˆìš”, í•œë²ˆ í’€ì–´ë³¼ê¹Œìš”?â€ ê°™ì€ ë©˜íŠ¸ë¥¼ ë§ë¶™ì´ì„¸ìš”."
        ),
    },
    "ntaejin": {
        "display": "íƒœì§„", "sex": "ë‚¨ì„±", "speaker": "ntaejin",
        "persona_rules": (
            "ë‹¹ì‹ ì€ ì—´ì •ì ì¸ ë‚¨ì ìŠ¤í¬ì¸  ì½”ì¹˜ì…ë‹ˆë‹¤. "
            "í•™ìƒì—ê²Œ ê°•ì˜ ë‚´ìš©ì„ ë§ˆì¹˜ í›ˆë ¨ì²˜ëŸ¼ ëŠë¼ê²Œ í•˜ë©°, í˜ ìˆê³  ì§ì„¤ì ì¸ ë§íˆ¬ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”. "
            "ì„¤ëª…ì€ â€œê¸°ë³¸ê¸° â†’ í›ˆë ¨ â†’ ì‘ìš©â€ ìˆœì„œë¡œ ì§„í–‰í•˜ê³ , ì–´ë ¤ìš´ ê°œë…ì„ ìŠ¤í¬ì¸  í›ˆë ¨ì— ë¹„ìœ í•˜ì„¸ìš”. "
            "í•­ìƒ ë™ê¸°ë¶€ì—¬ë¥¼ ì£¼ë©° â€œì¢‹ì•„! ë°”ë¡œ ê·¸ê±°ì•¼!â€, â€œë©ˆì¶”ì§€ ë§ˆ, ëê¹Œì§€ ê°€ë³´ì!â€ ê°™ì€ êµ¬í˜¸ë¥¼ í¬í•¨í•˜ì„¸ìš”."
        ),
    },
    "nwoojin": {
        "display": "ìš°ì§„", "sex": "ë‚¨ì„±", "speaker": "nwoojin",
        "persona_rules": (
            "ë‹¹ì‹ ì€ ì°¨ê°‘ê³  ë‚ ì¹´ë¡œìš´ ë‚¨ì ë¹„í‰ê°€í˜• ê°•ì‚¬ì…ë‹ˆë‹¤. "
            "í•™ìƒì—ê²Œ ë‹¨ì ì„ ìˆ¨ê¸°ì§€ ì•Šê³  ì†”ì§í•˜ê²Œ ì§€ì í•˜ì„¸ìš”. "
            "ì„¤ëª…ì€ í•µì‹¬ë§Œ ê°„ê²°í•˜ê²Œ ì „ë‹¬í•˜ë©°, ë¶€ì¡±í•œ ë¶€ë¶„ì´ ìˆìœ¼ë©´ â€œì´ê±´ ì „í˜€ ì¶©ë¶„í•˜ì§€ ì•Šë‹¤â€, "
            "â€œì´ ë¶€ë¶„ì„ ë°˜ë“œì‹œ ë³´ì™„í•´ì•¼ í•œë‹¤â€ì²˜ëŸ¼ ë‹¨í˜¸í•˜ê²Œ í‘œí˜„í•˜ì„¸ìš”. "
            "ë§ˆì§€ë§‰ì—ëŠ” ê°œì„  ë°©í–¥ì„ ì œì‹œí•˜ë©´ì„œ â€œë‹¤ì‹œ í•´ë³´ë¼â€ëŠ” ì‹ìœ¼ë¡œ ë„ì „ ì˜ì‹ì„ ë¶ˆëŸ¬ì¼ìœ¼í‚¤ì„¸ìš”."
        ),
    },
}
DEFAULT_PERSONA_KEY = os.getenv("DEFAULT_PERSONA", "ntaejin")
if DEFAULT_PERSONA_KEY not in PERSONAS:
    DEFAULT_PERSONA_KEY = "nminjeong"
P_DEFAULT = PERSONAS[DEFAULT_PERSONA_KEY]

# CLOVA Voice (Premium) endpoints
NCP_KEY_ID = os.getenv("NCP_CLOVA_KEY_ID")
NCP_KEY    = os.getenv("NCP_CLOVA_KEY")
TTS_PREMIUM_URL = "https://naveropenapi.apigw.ntruss.com/tts-premium/v1/tts"

# =========================
# 2) DB
# =========================
Base = declarative_base()
engine = create_engine(f"sqlite:///{SQLITE_PATH}", echo=False, future=True)
SessionLocal = sessionmaker(bind=engine, autocommit=False, autoflush=False)

class Interaction(Base):
    __tablename__ = "interactions"
    id = Column(Integer, primary_key=True)
    session_id = Column(String(64), index=True)
    doc_id = Column(String(64), index=True, nullable=True)
    role = Column(String(16))      # 'user' or 'assistant'
    content = Column(Text)
    refs = Column(Text)            # JSON string
    audio_path = Column(String(256), nullable=True)
    created_at = Column(DateTime, default=dt.datetime.utcnow)

class DocumentMeta(Base):
    __tablename__ = "documents"
    id = Column(Integer, primary_key=True)
    doc_id = Column(String(64), unique=True, index=True)
    filename = Column(String(256))
    script = Column(Text)          # (ì˜µì…˜) ìš”ì•½/ìŠ¤í¬ë¦½íŠ¸ ì €ì¥ìš©
    created_at = Column(DateTime, default=dt.datetime.utcnow)

Base.metadata.create_all(bind=engine)

def save_interaction(db, *, session_id: str, role: str, content: str,
                     doc_id: Optional[str] = None,
                     refs: Optional[Dict] = None,
                     audio_path: Optional[str] = None):
    it = Interaction(
        session_id=session_id,
        doc_id=doc_id,
        role=role,
        content=content,
        refs=json.dumps(refs, ensure_ascii=False) if refs else None,
        audio_path=audio_path
    )
    db.add(it)
    db.commit()

# =========================
# 3) FastAPI
# =========================
from fastapi.staticfiles import StaticFiles


app = FastAPI(title="RAG TeachKit (FAISS + Persona + Clova Voice TTS Premium)")
origins = ["*"]
app.add_middleware(
    CORSMiddleware,
    allow_origins=origins, allow_credentials=True,
    allow_methods=["*"], allow_headers=["*"],
)
app.mount("/static", StaticFiles(directory="static"), name="static")
templates = Jinja2Templates(directory="templates")


# =========================
# 4) LLM & Embeddings
# =========================
api_key = os.getenv("CLOVASTUDIO_API_KEY")
if not api_key:
    raise RuntimeError("í™˜ê²½ë³€ìˆ˜ CLOVASTUDIO_API_KEY ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
llm = ChatClovaX(model="HCX-007", api_key=api_key, temperature=0.2)
_base_embeddings = ClovaXEmbeddings(model="clir-emb-dolphin", api_key=api_key)

class RateLimitedEmbeddings(Embeddings):
    def __init__(self, base: Embeddings, throttle: float = 0.25,
                 base_delay: float = 0.6, max_retries: int = 6, batch_size: int = 16):
        self.base = base
        self.throttle = throttle
        self.base_delay = base_delay
        self.max_retries = max_retries
        self.batch_size = batch_size
    def _sleep(self):
        if self.throttle > 0: time.sleep(self.throttle)
    def _with_retry(self, func, *args, **kwargs):
        delay = self.base_delay
        for attempt in range(self.max_retries):
            try:
                return func(*args, **kwargs)
            except RateLimitError:
                time.sleep(delay); delay *= 2
            except Exception as e:
                if "429" in str(e):
                    time.sleep(delay); delay *= 2
                else:
                    raise
        return func(*args, **kwargs)
    def embed_query(self, text: str) -> List[float]:
        self._sleep(); return self._with_retry(self.base.embed_query, text)
    def embed_documents(self, texts: List[str]) -> List[List[float]]:
        out: List[List[float]] = []
        n = len(texts)
        for s in range(0, n, self.batch_size):
            batch = texts[s:s+self.batch_size]
            self._sleep()
            vecs = self._with_retry(self.base.embed_documents, batch)
            out.extend(vecs)
        return out

embeddings = RateLimitedEmbeddings(_base_embeddings, throttle=0.25, base_delay=0.6, max_retries=6, batch_size=16)

# =========================
# 5) VectorStore (FAISS)
# =========================
def _vs_path(doc_id: str) -> str:
    return os.path.join(VECTOR_DIR, doc_id)

def persist_faiss(vs: FAISS, doc_id: str):
    target = _vs_path(doc_id)
    os.makedirs(target, exist_ok=True)
    vs.save_local(target)

def load_faiss(doc_id: str) -> FAISS:
    path = _vs_path(doc_id)
    if not os.path.isdir(path):
        raise FileNotFoundError("Vector store not found. ë¨¼ì € PDFë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš”.")
    return FAISS.load_local(path, embeddings, allow_dangerous_deserialization=True)

# =========================
# 6) Prompts (ì²« ë²ˆì§¸ ì½”ë“œ ìŠ¤íƒ€ì¼)
# =========================
def build_qa_prompt(P: Dict[str, str]) -> ChatPromptTemplate:
    qa_system_template = f"""
ë„ˆëŠ” {P['sex']} í™”ìì˜, **{P['display']}** ìŠ¤íƒ€ì¼ AI íŠœí„°ì•¼.
ì•„ë˜ì˜ í˜ë¥´ì†Œë‚˜ ì§€ì¹¨ì„ ë°˜ë“œì‹œ ë”°ë¥¸ë‹¤:
{P['persona_rules']}

ëŒ€í™” ì „ë°˜ ê·œì¹™:
- ì¸ì‚¬/ìˆ˜ë½/ê°íƒ„/ì „í™˜ ë©˜íŠ¸ë¡œ ì‹œì‘ ê¸ˆì§€(ì˜ˆ: "ì¢‹ì•„", "ì˜¤ì¼€ì´", "ì•Œê² ì–´", "ì", "ê·¸ëŸ¼", "ì„¤ëª…í•´ì¤„ê²Œ").
- ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™”ì²´ë¡œ 3~6ë¬¸ì¥, ë¬¸ì¥ì€ ì§§ê²Œ.
- ëª©ë¡/ë²ˆí˜¸/ë§ˆí¬ë‹¤ìš´(#, ##, 1., - ë“±) ê¸ˆì§€.
- ì–´ë ¤ìš´ ìš©ì–´ëŠ” ì‰¬ìš´ ë§ë¡œ ë°”ë¡œ í’€ì–´ì¤˜.
- 4~7ë¬¸ì¥: í•µì‹¬ ìš”ì§€ â†’ ì‰¬ìš´ ì˜ˆì‹œ 1ê°œ â†’ ë§ˆì§€ë§‰ì— ì´í•´ í™•ì¸ ì§ˆë¬¸ 1ë¬¸ì¥.
- ğŸ”¥ "**í•µì‹¬**:" ê°™ì€ ê°•ì¡°í•˜ëŠ” ê°•ì¡°í•˜ëŠ” ë©˜íŠ¸ë¥¼ ì‚¬ìš©í•˜ì§€ë§ˆ.
    (ì˜ˆ:"**ì¤‘ìš”**: ê¸°íƒ€.." âŒ,
        "**ê°•ì¡°**: ê¸°íƒ€.." âŒ,
         **"ìŠ¤í¬ì¸  ë¹„ìœ **: ê°œë… ìŠ¤í‚¤ë§ˆê°€ íŒ€ ì „ëµì´ë¼ë©´, ë‚´ë¶€ ìŠ¤í‚¤ë§ˆëŠ” ì‹¤ì œ ê²½ê¸°ì¥ì—ì„œ ì„ ìˆ˜ë“¤ì˜ í¬ì§€ì…˜ ë°°ì¹˜ì™€ ì›€ì§ì„ ë°©ì‹ì´ì—ìš”." âŒ)
- "**ë¬¸ì¥**"ë¡œ ê°•ì¡°í•˜ëŠ” ë©˜íŠ¸ ì‚¬ìš©í•˜ì§€ë§ˆ.
ê°•ì˜ ë³¸ë¬¸ ì¶œë ¥ì´ ëë‚˜ë©´ ë°˜ë“œì‹œ ì•„ë˜ í˜•ì‹ì˜ ìµœì¢… ê²€í† ë¥¼ ë§ë¶™ì—¬:
###[ìµœì¢… ê²€í† ]
1. [ëª¨ë²” ë‹µì•ˆ ì˜ˆì‹œ]ì™€ ë¹„êµí•´ ì ì ˆí–ˆëŠ”ì§€ ê²€í† 
2. ì¶œì²˜ê°€ ì—…ë¡œë“œí•œ pdfíŒŒì¼ì˜ ë°ì´í„°ì¸ì§€ ê²€í†   
   (ì˜ˆ: "ìë£Œ p12ì— ë”°ë¥´ë©´, ë°ì´í„° ë² ì´ìŠ¤ì˜ ì¥ì ì€ ë°ì´í„°ì˜ ì¼ê´€ì„± ìœ ì§€ì™€ ë°ì´í„°ì˜ ë¬´ê²°ì„± ìœ ì§€ê°€ ìˆì–´." âœ…,  
        "ë°ì´í„°ë² ì´ìŠ¤ì˜ ì¥ì ì€ í‘œì¤€í™”ì•¼." âŒ)

- ì•„ë˜ ë¬¸ì„œ ë‚´ìš©ì— ê·¼ê±°í•´ì„œë§Œ ë‹µí•´. ì—†ìœ¼ë©´ "ìë£Œì—” ì´ ë‚´ìš©ì´ ì—†ì–´"ë¼ê³  ë§í•˜ê³ , ëŒ€ì‹  í•œ ì¤„ ì œì•ˆ.

ë¬¸ì„œ ë‚´ìš©:
{{context}}
"""
    return ChatPromptTemplate.from_messages([
        ("system", qa_system_template),
        ("human", "{question}"),
    ])


def build_lecture_prompt(P: Dict[str, str]) -> ChatPromptTemplate:
    lecture_system_template = f"""
ë„ˆëŠ” {P['sex']} í™”ìì˜, **{P['display']}** ìŠ¤íƒ€ì¼ AI íŠœí„°ì•¼.
ì•„ë˜ì˜ í˜ë¥´ì†Œë‚˜ ì§€ì¹¨ì„ ë°˜ë“œì‹œ ë”°ë¥¸ë‹¤:
{P['persona_rules']}

ì¶œë ¥ ê·œì¹™(ë°˜ë“œì‹œ ì¤€ìˆ˜):
- ì¸ì‚¬/ìˆ˜ë½/ê°íƒ„/ì „í™˜ ë©˜íŠ¸ë¡œ ì‹œì‘ ê¸ˆì§€(ì˜ˆ: "ì¢‹ì•„", "ì˜¤ì¼€ì´", "ì•Œê² ì–´", "ì", "ê·¸ëŸ¼", "ì„¤ëª…í•´ì¤„ê²Œ").
- ê³§ë°”ë¡œ ë‚´ìš©ìœ¼ë¡œ ì‹œì‘. ì²« ë¬¸ì¥ì€ ì£¼ì œ/í•µì‹¬ ê°œë…ìœ¼ë¡œ.
- ì§€ê¸ˆì€ p{{page_num}} ë‚´ìš©ë§Œ ì‚¬ìš©. ì•ë’¤ í˜ì´ì§€ ì‚¬ì „ ì–¸ê¸‰ ê¸ˆì§€.
- 4~7ë¬¸ì¥: í•µì‹¬ ìš”ì§€ â†’ ì‰¬ìš´ ì˜ˆì‹œ 1ê°œ â†’ ë§ˆì§€ë§‰ì— ì´í•´ í™•ì¸ ì§ˆë¬¸ 1ë¬¸ì¥.
- ëª©ë¡/ë²ˆí˜¸/ë§ˆí¬ë‹¤ìš´ ê¸ˆì§€. ì–´ë ¤ìš´ ìš©ì–´ëŠ” ë°”ë¡œ í’€ì–´ì„œ.
- ğŸ”¥ "**í•µì‹¬**:" ê°™ì€ ê°•ì¡°í•˜ëŠ” ê°•ì¡°í•˜ëŠ” ë©˜íŠ¸ë¥¼ ì‚¬ìš©í•˜ì§€ë§ˆ.
    (ì˜ˆ:"**ì¤‘ìš”**: ê¸°íƒ€.." âŒ,
        "**ê°•ì¡°**: ê¸°íƒ€.." âŒ,
         **"ìŠ¤í¬ì¸  ë¹„ìœ **: ê°œë… ìŠ¤í‚¤ë§ˆê°€ íŒ€ ì „ëµì´ë¼ë©´, ë‚´ë¶€ ìŠ¤í‚¤ë§ˆëŠ” ì‹¤ì œ ê²½ê¸°ì¥ì—ì„œ ì„ ìˆ˜ë“¤ì˜ í¬ì§€ì…˜ ë°°ì¹˜ì™€ ì›€ì§ì„ ë°©ì‹ì´ì—ìš”." âŒ)
- **ë¡œ ê°•ì¡°í•˜ëŠ” ë©˜íŠ¸ ì‚¬ìš©í•˜ì§€ë§ˆ.

ê°•ì˜ ë³¸ë¬¸ ì¶œë ¥ì´ ëë‚˜ë©´ ë°˜ë“œì‹œ ì•„ë˜ í˜•ì‹ì˜ ìµœì¢… ê²€í† ë¥¼ ë§ë¶™ì—¬:
###[ìµœì¢… ê²€í† ]
1. [ëª¨ë²” ë‹µì•ˆ ì˜ˆì‹œ]ì™€ ë¹„êµí•´ ì ì ˆí–ˆëŠ”ì§€ ê²€í† 
2. ì¶œì²˜ê°€ ì—…ë¡œë“œí•œ pdfíŒŒì¼ì˜ ë°ì´í„°ì¸ì§€ ê²€í†   
   (ì˜ˆ: "ìë£Œ p12ì— ë”°ë¥´ë©´, ë°ì´í„° ë² ì´ìŠ¤ì˜ ì¥ì ì€ ë°ì´í„°ì˜ ì¼ê´€ì„± ìœ ì§€ì™€ ë°ì´í„°ì˜ ë¬´ê²°ì„± ìœ ì§€ê°€ ìˆì–´." âœ…,  
        "ë°ì´í„°ë² ì´ìŠ¤ì˜ ì¥ì ì€ í‘œì¤€í™”ì•¼." âŒ)

í˜„ì¬ í˜ì´ì§€ í…ìŠ¤íŠ¸:
{{context}}
"""
    return ChatPromptTemplate.from_messages([
        ("system", lecture_system_template),
        ("human", "ê°•ì˜ ë³¸ë¬¸ë§Œ ì¶œë ¥."),
    ])


# =========================
# 7) CSR & TTS (í”„ë¦¬ë¯¸ì—„, ë¶„í• )
# =========================
def recognize_csr(audio_path: str) -> str:
    CSR_URL = "https://naveropenapi.apigw.ntruss.com/recog/v1/stt?lang=Kor"
    if not (NCP_KEY_ID and NCP_KEY):
        return ""
    headers = {
        "X-NCP-APIGW-API-KEY-ID": NCP_KEY_ID,
        "X-NCP-APIGW-API-KEY": NCP_KEY,
        "Content-Type": "application/octet-stream",
    }
    with open(audio_path, "rb") as f:
        data = f.read()
    resp = requests.post(CSR_URL, headers=headers, data=data, timeout=60)
    if resp.status_code != 200:
        return ""
    try:
        return resp.json().get("text", "") or ""
    except Exception:
        return resp.text.strip()

def split_for_tts(text: str, max_len: int = 2800) -> List[str]:
    if len(text) <= max_len:
        return [text]
    parts, cur = [], []
    cur_len = 0
    for sent in re.split(r'(?<=[.?!â€¦]|[ê°€-í£]\))\s+', text):
        if cur_len + len(sent) + 1 > max_len and cur:
            parts.append(" ".join(cur))
            cur, cur_len = [], 0
        cur.append(sent)
        cur_len += len(sent) + 1
    if cur:
        parts.append(" ".join(cur))
    return parts

def synthesize_clova_voice_premium_mp3(
    text: str,
    speaker: str,
    speed: int = 0,
    pitch: int = 0,
    volume: int = 0,
    audio_dir: str = AUDIO_DIR,
) -> List[str]:
    """
    CLOVA Voice Premium TTS (mp3) + 2800ì ë¶„í• . ë‹¤ì¤‘ íŒŒì¼ ê²½ë¡œ ë°˜í™˜.
    """
    if not (NCP_KEY_ID and NCP_KEY):
        return []
    os.makedirs(audio_dir, exist_ok=True)
    headers = {
        "X-NCP-APIGW-API-KEY-ID": NCP_KEY_ID,
        "X-NCP-APIGW-API-KEY": NCP_KEY,
        "Content-Type": "application/x-www-form-urlencoded; charset=utf-8",
    }
    chunks = split_for_tts(text, max_len=2800)
    out_paths = []
    delay = 0.6
    for idx, chunk in enumerate(chunks, start=1):
        data = {
            "speaker": speaker,
            "text": chunk,
            "format": "mp3",
            "speed": str(speed),
            "pitch": str(pitch),
            "volume": str(volume),
        }
        for attempt in range(6):
            resp = requests.post(TTS_PREMIUM_URL, headers=headers, data=data, timeout=60)
            if resp.status_code == 200:
                fname = f"{uuid.uuid4().hex}"
                if len(chunks) == 1:
                    fname = f"{fname}.mp3"
                else:
                    fname = f"{fname}_part{idx}.mp3"
                path = os.path.join(audio_dir, fname)
                with open(path, "wb") as f:
                    f.write(resp.content)
                out_paths.append(path)
                break
            elif resp.status_code in (429, 503):
                time.sleep(delay); delay *= 2
            else:
                raise RuntimeError(f"TTS ì‹¤íŒ¨ {resp.status_code}: {resp.text}")
    return out_paths

# =========================
# 8) Units (í˜ì´ì§€ ë‹¨ì›)
# =========================
UNITS_BY_DOC: Dict[str, List[Dict[str, Any]]] = {}  # doc_id -> units(list)
LECTURE_STATE: Dict[str, int] = {}                  # session_id -> cur index

def build_units_from_documents(documents) -> List[Dict[str, Any]]:
    """í˜ì´ì§€ë³„ í…ìŠ¤íŠ¸ë¥¼ ëª¨ì•„ ë‹¨ì› ìƒì„± (ì²« ë²ˆì§¸ ì½”ë“œ ìŠ¤íƒ€ì¼, 4000ì ì œí•œ)."""
    page_buckets: Dict[int, List[str]] = defaultdict(list)
    for d in documents:
        p = int(d.metadata.get("page", 0))
        page_buckets[p].append(d.page_content)
    units = []
    for p in sorted(page_buckets.keys()):
        text = "\n".join(page_buckets[p]).strip()
        # [FIX] ìŠ¤ìº” PDF ë°©ì§€: ì™„ì „ ë¹ˆ í˜ì´ì§€ëŠ” ìŠ¤í‚µí•˜ì§€ ë§ê³  ì•Œë¦¼ ë¬¸êµ¬ë¡œ ëŒ€ì²´
        if not text:
            text = "(ì´ í˜ì´ì§€ëŠ” ì¶”ì¶œëœ í…ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤. ìŠ¤ìº” PDFì¼ ìˆ˜ ìˆì–´ìš”.)"
        if len(text) > 4000:
            text = text[:4000] + "\n(ì´í•˜ ìƒëµ)"
        units.append({"page0": p, "page": p + 1, "text": text})
    return units

def teach_unit_text(P: Dict[str, str], unit: Dict[str, Any]) -> str:
    prompt = build_lecture_prompt(P)
    msgs = prompt.format_messages(page_num=unit["page"], context=unit["text"])
    resp = llm.invoke(msgs)
    return getattr(resp, "content", str(resp))

# =========================
# 9) RetrievalQA Builder
# =========================
def build_qa_chain(P: Dict[str, str], vectorstore: FAISS) -> RetrievalQA:
    retriever = vectorstore.as_retriever(search_kwargs={"k": 5})
    prompt = build_qa_prompt(P)
    return RetrievalQA.from_chain_type(
        llm=llm,
        chain_type="stuff",
        retriever=retriever,
        return_source_documents=True,
        chain_type_kwargs={
            "prompt": prompt,
            "document_variable_name": "context",   # ì§€ê¸ˆ ì½”ë“œ
            # â†“ ì¶”ê°€
            #"input_key": "query",                  # ì§ˆë¬¸ ì…ë ¥ í•„ë“œ ëª…ì‹œ
            #"output_key": "result",                # ì¶œë ¥ í•„ë“œ ëª…ì‹œ
        },
    )

# =========================
# 10) Schemas
# =========================
class ChatReq(BaseModel):
    session_id: str
    question: str
    doc_id: Optional[str] = "current_doc"
    want_tts: bool = False
    persona: Optional[str] = None
    tts_speed: Optional[int] = None
    tts_volume: Optional[int] = None
    tts_pitch: Optional[int] = None

class ChatResp(BaseModel):
    answer: str
    audio_url: Optional[str] = None
    audio_urls: Optional[List[str]] = None
    # [FIX] ê°€ë³€ ë””í´íŠ¸ ì œê±°
    used_refs: Optional[List[Dict[str, Any]]] = Field(default=None)

# =========================
# 11) Pages
# =========================
@app.get("/", response_class=HTMLResponse)
async def home(request: Request):
    return templates.TemplateResponse(
        "index.html",
        {"request": request, "PERSONAS": PERSONAS}
    )
@app.get("/chat", response_class=HTMLResponse)
async def chat(request: Request, teacher: str):
    teacher_info = PERSONAS.get(teacher)
    if not teacher_info:
        return HTMLResponse(content=f"<h1>ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ê°•ì‚¬: {teacher}</h1>", status_code=404)
    return templates.TemplateResponse(
        "chat.html",
        {"request": request, "teacher": teacher_info, "teacher_key": teacher}
    )

# =========================
# 12) PDF Ingest â†’ FAISS + Units
# =========================
@app.post("/ingest/pdf")
async def ingest_pdf_api(file: UploadFile = File(...)):
    pdf_path = os.path.join(UPLOAD_DIR, file.filename)
    with open(pdf_path, "wb") as f:
        f.write(await file.read())

    loader = PyPDFLoader(pdf_path)
    documents = loader.load()

    splitter = RecursiveCharacterTextSplitter(
        chunk_size=400, chunk_overlap=80, separators=["\n\n", "\n", " ", ""]
    )
    chunks = [d for d in splitter.split_documents(documents) if len(d.page_content.strip()) >= 20]

    doc_id = "current_doc"
    shutil.rmtree(_vs_path(doc_id), ignore_errors=True)
    os.makedirs(_vs_path(doc_id), exist_ok=True)

    # === ì„ë² ë”© í™•ì¸ ë¶€ë¶„ ì¶”ê°€ ===
    sample_text = chunks[0].page_content[:200]  # ì²« ì²­í¬ ì• 200ìë§Œ í™•ì¸
    sample_vector = embeddings.embed_query(sample_text)  # 1ì°¨ì› list[float]

    vs = FAISS.from_documents(chunks, embedding=embeddings)
    persist_faiss(vs, doc_id)

    UNITS_BY_DOC[doc_id] = build_units_from_documents(documents)

    return {
        "doc_id": doc_id,
        "pages": len(documents),
        "chunks": len(chunks),
        "sample_text": sample_text,
        "sample_vector_dim": len(sample_vector),
        "sample_vector": sample_vector[:10],  # ì• 10ì°¨ì›ë§Œ í™•ì¸
        "message": "PDF ì—…ë¡œë“œ ë° ë²¡í„° ì €ì¥ ì™„ë£Œ"
    }


# =========================
# 13) Chat (ëª…ë ¹ì–´/ê°•ì˜/RAG â†’ TTS)
# =========================
def _pick_persona(req_persona: Optional[str]) -> Dict[str, str]:
    key = (req_persona or DEFAULT_PERSONA_KEY).strip()
    return PERSONAS.get(key, P_DEFAULT)

def _tts_paths_to_urls(paths: List[str]) -> Tuple[Optional[str], Optional[List[str]]]:
    if not paths:
        return None, None
    urls = [f"/audio/{os.path.basename(p)}" for p in paths]
    return urls[0], urls

@app.post("/chat", response_model=ChatResp)
async def chat_api(req: ChatReq):
    db = SessionLocal()
    doc_id = req.doc_id or "current_doc"
    P = _pick_persona(req.persona)

    # ë²¡í„°ìŠ¤í† ì–´ ë¡œë“œ
    try:
        vectorstore = load_faiss(doc_id)
    except Exception:
        db.close()  # [FIX] ëˆ„ìˆ˜ ë°©ì§€
        return {"answer": "â— í•´ë‹¹ ë¬¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € PDFë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš”.", "used_refs": []}

    # user log
    save_interaction(db, session_id=req.session_id, role="user",
                     content=req.question, doc_id=doc_id)

    raw = req.question.strip()
    audio_url, audio_urls, audio_path = None, None, None

    # ===== ê°•ì˜ ëª…ë ¹ì–´ ì²˜ë¦¬ =====
    if raw in ("/teach", "/next", "/prev") or raw.startswith("/goto"):
        units = UNITS_BY_DOC.get(doc_id)
        if not units:
            try:
                metas = SessionLocal().query(DocumentMeta).filter_by(doc_id=doc_id).first()
                filename = metas.filename if metas else None
                if filename:
                    loader = PyPDFLoader(os.path.join(UPLOAD_DIR, filename))
                    documents = loader.load()
                    UNITS_BY_DOC[doc_id] = build_units_from_documents(documents)
                    units = UNITS_BY_DOC[doc_id]
            except Exception:
                pass
        if not units:
            db.close()
            return {"answer": "ê°•ì˜ ë‹¨ì›ì´ ì¤€ë¹„ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤. PDFë¥¼ ë‹¤ì‹œ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.", "used_refs": []}

        cur = LECTURE_STATE.get(req.session_id, 0)

        if raw == "/prev":
            cur = max(0, cur - 1)
        elif raw == "/next":
            if cur < len(units) - 1:
                cur += 1
        elif raw.startswith("/goto"):
            m = re.search(r"/goto\s+(\d+)", raw)
            if m:
                page_target = int(m.group(1))
                idx = None
                for i, u in enumerate(units):
                    if u["page"] == page_target:
                        idx = i
                        break
                if idx is None:
                    if page_target <= units[0]["page"]:
                        idx = 0
                    elif page_target >= units[-1]["page"]:
                        idx = len(units) - 1
                    else:
                        idx = min(range(len(units)), key=lambda i: abs(units[i]["page"] - page_target))
                cur = idx

        LECTURE_STATE[req.session_id] = cur
        unit = units[cur]

        answer = teach_unit_text(P, unit)
        used_refs = [{"type": "page", "page": unit["page"]}]

        if req.want_tts:
            speed = req.tts_speed if req.tts_speed is not None else 0
            volume = req.tts_volume if req.tts_volume is not None else 0
            pitch = req.tts_pitch if req.tts_pitch is not None else 0
            paths = synthesize_clova_voice_premium_mp3(
                answer, speaker=P["speaker"], speed=speed, pitch=pitch, volume=volume
            )
            audio_url, audio_urls = _tts_paths_to_urls(paths)
            audio_path = paths[0] if paths else None
        else:
            audio_url, audio_urls, audio_path = None, None, None

        save_interaction(
            db,
            session_id=req.session_id,
            role="assistant",
            content=answer,
            doc_id=doc_id,
            refs={"mode": "lecture", "page": unit["page"]},
            audio_path=audio_path,
        )
        db.close()
        return ChatResp(answer=answer, audio_url=audio_url, audio_urls=audio_urls, used_refs=used_refs)

    # ===== Q&A (RetrievalQA) =====
    try:
        chain = build_qa_chain(P, vectorstore)
        res = chain({"query": raw})

        # [FIX] LangChain ë²„ì „ í˜¸í™˜: result / output_text / answer ëª¨ë‘ ëŒ€ì‘
        answer = (
            (res.get("result") or res.get("output_text") or res.get("answer") or "")
        ).strip()
        if not answer:
            answer = "ìë£Œì—” ì´ ë‚´ìš©ì´ ì—†ì–´. ëŒ€ì‹  ê´€ë ¨ í‚¤ì›Œë“œë¥¼ ë°”ê¿”ì„œ ë‹¤ì‹œ ë¬¼ì–´ë³´ëŠ” ê±´ ì–´ë•Œìš”?"

        srcs = res.get("source_documents", []) or []

        used_refs: List[Dict[str, Any]] = []
        for d in srcs:
            try:
                p0 = int(d.metadata.get("page", 0))
            except Exception:
                p0 = 0
            preview = (d.page_content or "").strip().replace("\n", " ")
            if len(preview) > 160:
                preview = preview[:160] + "â€¦"
            used_refs.append({"type": "source", "page": p0 + 1, "preview": preview})

        # ì¤‘ë³µ í˜ì´ì§€ ì œê±°
        seen = set()
        deduped = []
        for r in used_refs:
            key = (r["type"], r["page"])
            if key not in seen:
                deduped.append(r); seen.add(key)
        used_refs = deduped[:5]

        if req.want_tts:
            speed = req.tts_speed if req.tts_speed is not None else 0
            volume = req.tts_volume if req.tts_volume is not None else 0
            pitch = req.tts_pitch if req.tts_pitch is not None else 0
            paths = synthesize_clova_voice_premium_mp3(
                answer, speaker=P["speaker"], speed=speed, pitch=pitch, volume=volume
            )
            audio_url, audio_urls = _tts_paths_to_urls(paths)
            audio_path = paths[0] if paths else None
        else:
            audio_url, audio_urls, audio_path = None, None, None

        save_interaction(
            db,
            session_id=req.session_id,
            role="assistant",
            content=answer,
            doc_id=doc_id,
            refs={"mode": "qa", "used_refs": used_refs},
            audio_path=audio_path,
        )
        db.close()
        return ChatResp(answer=answer, audio_url=audio_url, audio_urls=audio_urls, used_refs=used_refs)

    except Exception as e:
        err_msg = f"ë‹µë³€ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}"
        save_interaction(db, session_id=req.session_id, role="assistant", content=err_msg, doc_id=doc_id)
        db.close()
        return ChatResp(answer=err_msg, used_refs=[])

# =========================
# 14) Audio Static Serving
# =========================
@app.get("/audio/{filename}")
async def get_audio(filename: str):
    from fastapi import HTTPException
    path = os.path.join(AUDIO_DIR, filename)
    if not os.path.isfile(path):
        raise HTTPException(status_code=404, detail="Audio not found")
    return FileResponse(path, media_type="audio/mpeg", filename=filename)

# =========================
# 15) Lecture Helpers
# =========================
@app.post("/lecture/reset")
async def lecture_reset(session_id: str):
    LECTURE_STATE.pop(session_id, None)
    return {"message": "ok", "session_id": session_id, "state": "reset"}

@app.get("/lecture/status")
async def lecture_status(session_id: str):
    cur = LECTURE_STATE.get(session_id, 0)
    return {"session_id": session_id, "current_index": cur}

# =========================
# 16) Persona Helpers
# =========================
@app.get("/personas")
async def list_personas():
    out = []
    for k, v in PERSONAS.items():
        out.append({"key": k, "display": v["display"], "sex": v["sex"], "speaker": v["speaker"]})
    return {"personas": out}

# =========================
# 17) Local run (optional)
# =========================
if __name__ == "__main__":
    import uvicorn
    uvicorn.run("app:app", host="0.0.0.0", port=8000, reload=True)
