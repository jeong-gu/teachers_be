# -*- coding: utf-8 -*-
import os
import re
import uuid
import json
import time
import shutil
import datetime as dt
from pathlib import Path
from typing import Optional, List, Dict, Any, Tuple
from collections import defaultdict

from fastapi import FastAPI, UploadFile, File, Request
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import FileResponse, HTMLResponse
from fastapi.templating import Jinja2Templates

from pydantic import BaseModel, Field
from dotenv import load_dotenv, find_dotenv

from sqlalchemy import create_engine, Column, Integer, String, Text, DateTime
from sqlalchemy.orm import sessionmaker, declarative_base

# LangChain & Clova
from openai import RateLimitError
from langchain_naver import ChatClovaX, ClovaXEmbeddings
from langchain_community.document_loaders import PyPDFLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import FAISS
from langchain.prompts import ChatPromptTemplate
from langchain.chains import RetrievalQA
from langchain_core.embeddings import Embeddings

import requests

# =========================
# 0) ENV & PATHS
# =========================
load_dotenv(find_dotenv())

ROOT_DIR   = os.path.abspath(os.path.dirname(__file__))
DATA_DIR   = os.path.abspath(os.path.join(ROOT_DIR, "..", "data"))
UPLOAD_DIR = os.path.join(DATA_DIR, "uploads")
AUDIO_DIR  = os.path.join(DATA_DIR, "audio")
VECTOR_DIR = os.getenv("VECTOR_DIR", os.path.join(DATA_DIR, "faiss"))
SQLITE_PATH = os.getenv("SQLITE_PATH", os.path.join(DATA_DIR, "app.db"))

os.makedirs(UPLOAD_DIR, exist_ok=True)
os.makedirs(AUDIO_DIR, exist_ok=True)
os.makedirs(VECTOR_DIR, exist_ok=True)

# =========================
# 1) Persona & TTS Config
# =========================
PERSONAS: Dict[str, Dict[str, str]] = {
    "ngoeun": {
        "display": "ê³ ì€", "sex": "ì—¬ì„±", "speaker": "ngoeun",
        "persona_rules": (
            "ë‹¹ì‹ ì€ ì¹œì ˆí•˜ê³  ë”°ëœ»í•œ ì—¬ì ì„ ìƒë‹˜ì…ë‹ˆë‹¤. "
            "í•™ìƒì´ í¸ì•ˆí•˜ê²Œ ëŠë‚„ ìˆ˜ ìˆë„ë¡ ì°¨ë¶„í•˜ê³  ë¶€ë“œëŸ¬ìš´ ë§íˆ¬ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”. "
            "ì–´ë ¤ìš´ ê°œë…ì€ ê¸°ì´ˆë¶€í„° ì°¨ê·¼ì°¨ê·¼ ì„¤ëª…í•˜ê³ , ì´í•´ê°€ ì˜ ë˜ë„ë¡ ì˜ˆì‹œë¥¼ ë“¤ì–´ì£¼ì„¸ìš”. "
            "ë§ˆì§€ë§‰ì—ëŠ” â€œë„ˆë¬´ ì˜í–ˆì–´ìš”!â€, â€œì¡°ê¸ˆì”© ë‚˜ì•„ì§€ê³  ìˆì–´ìš”â€ ê°™ì€ ê²©ë ¤ ë©˜íŠ¸ë¥¼ ë°˜ë“œì‹œ í¬í•¨í•˜ì„¸ìš”."
        ),
    },
    "nkyuwon": {
        "display": "ê·œì›", "sex": "ë‚¨ì„±", "speaker": "nkyuwon",
        "persona_rules": (
            "ë‹¹ì‹ ì€ ê°™ì€ ë˜ë˜ ì¹œêµ¬ì²˜ëŸ¼ ì¹œê·¼í•˜ê³  í¸ì•ˆí•œ í†¤ìœ¼ë¡œ ê°€ë¥´ì³ì£¼ëŠ” ì—­í• ì…ë‹ˆë‹¤. "
            "ì „ë¬¸ì ì¸ ìš©ì–´ë¥¼ ì“°ê¸°ë³´ë‹¤ëŠ” ì¼ìƒì ì¸ ì–¸ì–´ì™€ ë¹„ìœ ë¥¼ í™œìš©í•´ ì„¤ëª…í•˜ì„¸ìš”. "
            "ì–´ë ¤ìš´ ê°œë…ì´ ë‚˜ì˜¤ë©´ â€œì´ê±°ëŠ” ë§ˆì¹˜ â—‹â—‹ ê°™ì€ ê±°ì•¼â€ ì‹ìœ¼ë¡œ ì‰½ê²Œ í’€ì–´ì£¼ì„¸ìš”. "
            "í•™ìƒì´ ë¶€ë‹´ì„ ëŠë¼ì§€ ì•Šë„ë¡ ê°€ë³ê³  ìºì£¼ì–¼í•œ ë¶„ìœ„ê¸°ë¥¼ ìœ ì§€í•˜ì„¸ìš”."
        ),
    },
    "nminjeong": {
        "display": "ë¯¼ì •", "sex": "ì—¬ì„±", "speaker": "nminjeong",
        "persona_rules": (
            "ë‹¹ì‹ ì€ ì¹´ë¦¬ìŠ¤ë§ˆ ìˆê³  ì„íŒ©íŠ¸ ìˆëŠ” ì¼íƒ€ê°•ì‚¬ ìŠ¤íƒ€ì¼ì˜ ê°•ì‚¬ì…ë‹ˆë‹¤. "
            "ë¹ ë¥¸ í…œí¬ì™€ ê°•í•œ ìì‹ ê°ìœ¼ë¡œ í•µì‹¬ë§Œ ì½• ì§‘ì–´ ì„¤ëª…í•˜ì„¸ìš”. "
            "ë¶ˆí•„ìš”í•œ ë§ì€ ì¤„ì´ê³ , â€œì´ ë¶€ë¶„ì€ ë¬´ì¡°ê±´ ì™¸ì›Œì•¼ í•œë‹¤â€, â€œì´ê±° ì‹œí—˜ì— 100% ë‚˜ì˜¨ë‹¤â€ ê°™ì€ ê°•ì¡° ë©˜íŠ¸ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”. "
            "ê°€ë”ì€ í•™ìƒì„ ê¸´ì¥ì‹œí‚¤ë©´ì„œë„ ë™ê¸°ë¶€ì—¬ê°€ ë  ìˆ˜ ìˆë„ë¡ â€œì´ê±¸ ëª¨ë¥´ë©´ í°ì¼ ë‚©ë‹ˆë‹¤â€ ê°™ì€ ë©˜íŠ¸ë¥¼ ë„£ìœ¼ì„¸ìš”."
        ),
    },
    "nheera": {
        "display": "í¬ë¼", "sex": "ì—¬ì„±", "speaker": "nheera",
        "persona_rules": (
            "ë‹¹ì‹ ì€ ì°¨ë¶„í•˜ê³  ë…¼ë¦¬ì ì¸ ë¶„ì„í˜• íŠœí„°ì…ë‹ˆë‹¤. "
            "í•™ìƒì´ ìŠ¤ìŠ¤ë¡œ ì‚¬ê³ í•  ìˆ˜ ìˆë„ë¡ ì§ˆë¬¸ì„ ë˜ì§€ë©° ì„¤ëª…ì„ ì´ëŒì–´ê°€ì„¸ìš”. "
            "ì„¤ëª…ì€ 'í•µì‹¬ ìš”ì•½ â†’ ë‹¨ê³„ì  ë¶„ì„ â†’ ê´€ë ¨ ì§ˆë¬¸ â†’ ì •ë‹µ ë° í•´ì„¤' ìˆœì„œë¡œ ì§„í–‰í•©ë‹ˆë‹¤. "
            "ë³µì¡í•œ ê°œë…ì€ ë„ì‹ì Â·ë‹¨ê³„ì  ì–¸ì–´ë¡œ ë¶„í•´í•´ ì£¼ë©°, ë§ˆì§€ë§‰ì—ëŠ” â€œì´ì œ ë‹¹ì‹  ì°¨ë¡€ì˜ˆìš”, í•œë²ˆ í’€ì–´ë³¼ê¹Œìš”?â€ ê°™ì€ ë©˜íŠ¸ë¥¼ ë§ë¶™ì´ì„¸ìš”."
        ),
    },
    "ntaejin": {
        "display": "íƒœì§„", "sex": "ë‚¨ì„±", "speaker": "ntaejin",
        "persona_rules": (
            "ë‹¹ì‹ ì€ ì—´ì •ì ì¸ ë‚¨ì ìŠ¤í¬ì¸  ì½”ì¹˜ì…ë‹ˆë‹¤. "
            "í•™ìƒì—ê²Œ ê°•ì˜ ë‚´ìš©ì„ ë§ˆì¹˜ í›ˆë ¨ì²˜ëŸ¼ ëŠë¼ê²Œ í•˜ë©°, í˜ ìˆê³  ì§ì„¤ì ì¸ ë§íˆ¬ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”. "
            "ì„¤ëª…ì€ â€œê¸°ë³¸ê¸° â†’ í›ˆë ¨ â†’ ì‘ìš©â€ ìˆœì„œë¡œ ì§„í–‰í•˜ê³ , ì–´ë ¤ìš´ ê°œë…ì„ ìŠ¤í¬ì¸  í›ˆë ¨ì— ë¹„ìœ í•˜ì„¸ìš”. "
            "í•­ìƒ ë™ê¸°ë¶€ì—¬ë¥¼ ì£¼ë©° â€œì¢‹ì•„! ë°”ë¡œ ê·¸ê±°ì•¼!â€, â€œë©ˆì¶”ì§€ ë§ˆ, ëê¹Œì§€ ê°€ë³´ì!â€ ê°™ì€ êµ¬í˜¸ë¥¼ í¬í•¨í•˜ì„¸ìš”."
        ),
    },
    "nmovie": {
        "display": "ìš°ì§„", "sex": "ë‚¨ì„±", "speaker": "nmovie",
        "persona_rules": (
            "ë‹¹ì‹ ì€ ì°¨ê°‘ê³  ë‚ ì¹´ë¡œìš´ ë‚¨ì ë¹„í‰ê°€í˜• ê°•ì‚¬ì…ë‹ˆë‹¤. "
            "í•™ìƒì—ê²Œ ë‹¨ì ì„ ìˆ¨ê¸°ì§€ ì•Šê³  ì†”ì§í•˜ê²Œ ì§€ì í•˜ì„¸ìš”. "
            "ì„¤ëª…ì€ í•µì‹¬ë§Œ ê°„ê²°í•˜ê²Œ ì „ë‹¬í•˜ë©°, ë¶€ì¡±í•œ ë¶€ë¶„ì´ ìˆìœ¼ë©´ â€œì´ê±´ ì „í˜€ ì¶©ë¶„í•˜ì§€ ì•Šë‹¤â€, "
            "â€œì´ ë¶€ë¶„ì„ ë°˜ë“œì‹œ ë³´ì™„í•´ì•¼ í•œë‹¤â€ì²˜ëŸ¼ ë‹¨í˜¸í•˜ê²Œ í‘œí˜„í•˜ì„¸ìš”. "
            "ë§ˆì§€ë§‰ì—ëŠ” ê°œì„  ë°©í–¥ì„ ì œì‹œí•˜ë©´ì„œ â€œë‹¤ì‹œ í•´ë³´ë¼â€ëŠ” ì‹ìœ¼ë¡œ ë„ì „ ì˜ì‹ì„ ë¶ˆëŸ¬ì¼ìœ¼í‚¤ì„¸ìš”."
        ),
    },
}
DEFAULT_PERSONA_KEY = os.getenv("DEFAULT_PERSONA", "ntaejin")
if DEFAULT_PERSONA_KEY not in PERSONAS:
    DEFAULT_PERSONA_KEY = "nminjeong"
P_DEFAULT = PERSONAS[DEFAULT_PERSONA_KEY]

# CLOVA Voice (Premium) endpoints
NCP_KEY_ID = os.getenv("NCP_CLOVA_KEY_ID")
NCP_KEY    = os.getenv("NCP_CLOVA_KEY")
TTS_PREMIUM_URL = "https://naveropenapi.apigw.ntruss.com/tts-premium/v1/tts"

# =========================
# 2) DB
# =========================
Base = declarative_base()
engine = create_engine(f"sqlite:///{SQLITE_PATH}", echo=False, future=True)
SessionLocal = sessionmaker(bind=engine, autocommit=False, autoflush=False)

class Interaction(Base):
    __tablename__ = "interactions"
    id = Column(Integer, primary_key=True)
    session_id = Column(String(64), index=True)
    doc_id = Column(String(64), index=True, nullable=True)
    role = Column(String(16))      # 'user' or 'assistant'
    content = Column(Text)
    refs = Column(Text)            # JSON string
    audio_path = Column(String(256), nullable=True)
    created_at = Column(DateTime, default=dt.datetime.utcnow)

class DocumentMeta(Base):
    __tablename__ = "documents"
    id = Column(Integer, primary_key=True)
    doc_id = Column(String(64), unique=True, index=True)
    filename = Column(String(256))
    script = Column(Text)          # (ì˜µì…˜) ìš”ì•½/ìŠ¤í¬ë¦½íŠ¸ ì €ì¥ìš©
    created_at = Column(DateTime, default=dt.datetime.utcnow)

Base.metadata.create_all(bind=engine)

def save_interaction(db, *, session_id: str, role: str, content: str,
                     doc_id: Optional[str] = None,
                     refs: Optional[Dict] = None,
                     audio_path: Optional[str] = None):
    it = Interaction(
        session_id=session_id,
        doc_id=doc_id,
        role=role,
        content=content,
        refs=json.dumps(refs, ensure_ascii=False) if refs else None,
        audio_path=audio_path
    )
    db.add(it)
    db.commit()

# =========================
# 3) FastAPI
# =========================
from fastapi.staticfiles import StaticFiles


app = FastAPI(title="RAG TeachKit (FAISS + Persona + Clova Voice TTS Premium)")
origins = ["*"]
app.add_middleware(
    CORSMiddleware,
    allow_origins=origins, allow_credentials=True,
    allow_methods=["*"], allow_headers=["*"],
)
app.mount("/static", StaticFiles(directory="static"), name="static")
templates = Jinja2Templates(directory="templates")


# =========================
# 4) LLM & Embeddings
# =========================
api_key = os.getenv("CLOVASTUDIO_API_KEY")
if not api_key:
    raise RuntimeError("í™˜ê²½ë³€ìˆ˜ CLOVASTUDIO_API_KEY ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
llm = ChatClovaX(model="HCX-007", api_key=api_key, temperature=0.2)
_base_embeddings = ClovaXEmbeddings(model="clir-emb-dolphin", api_key=api_key)

class RateLimitedEmbeddings(Embeddings):
    def __init__(self, base: Embeddings, throttle: float = 0.25,
                 base_delay: float = 0.6, max_retries: int = 6, batch_size: int = 16):
        self.base = base
        self.throttle = throttle
        self.base_delay = base_delay
        self.max_retries = max_retries
        self.batch_size = batch_size
    def _sleep(self):
        if self.throttle > 0: time.sleep(self.throttle)
    def _with_retry(self, func, *args, **kwargs):
        delay = self.base_delay
        for attempt in range(self.max_retries):
            try:
                return func(*args, **kwargs)
            except RateLimitError:
                time.sleep(delay); delay *= 2
            except Exception as e:
                if "429" in str(e):
                    time.sleep(delay); delay *= 2
                else:
                    raise
        return func(*args, **kwargs)
    def embed_query(self, text: str) -> List[float]:
        self._sleep(); return self._with_retry(self.base.embed_query, text)
    def embed_documents(self, texts: List[str]) -> List[List[float]]:
        out: List[List[float]] = []
        n = len(texts)
        for s in range(0, n, self.batch_size):
            batch = texts[s:s+self.batch_size]
            self._sleep()
            vecs = self._with_retry(self.base.embed_documents, batch)
            out.extend(vecs)
        return out

embeddings = RateLimitedEmbeddings(_base_embeddings, throttle=0.25, base_delay=0.6, max_retries=6, batch_size=16)

# =========================
# 5) VectorStore (FAISS)
# =========================
def _vs_path(doc_id: str) -> str:
    return os.path.join(VECTOR_DIR, doc_id)

def persist_faiss(vs: FAISS, doc_id: str):
    target = _vs_path(doc_id)
    os.makedirs(target, exist_ok=True)
    vs.save_local(target)

def load_faiss(doc_id: str) -> FAISS:
    path = _vs_path(doc_id)
    if not os.path.isdir(path):
        raise FileNotFoundError("Vector store not found. ë¨¼ì € PDFë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš”.")
    return FAISS.load_local(path, embeddings, allow_dangerous_deserialization=True)

# =========================
# 6) Prompts (ì²« ë²ˆì§¸ ì½”ë“œ ìŠ¤íƒ€ì¼)
# =========================
def build_qa_prompt(P: Dict[str, str]) -> ChatPromptTemplate:
    qa_system_template = f"""
ë„ˆëŠ” {P['sex']} í™”ìì˜, **{P['display']}** ìŠ¤íƒ€ì¼ AI íŠœí„°ì•¼.
ì•„ë˜ì˜ í˜ë¥´ì†Œë‚˜ ì§€ì¹¨ì„ ë°˜ë“œì‹œ ë”°ë¥¸ë‹¤:
{P['persona_rules']}

ëŒ€í™” ì „ë°˜ ê·œì¹™:
- ì¸ì‚¬/ìˆ˜ë½/ê°íƒ„/ì „í™˜ ë©˜íŠ¸ë¡œ ì‹œì‘ ê¸ˆì§€(ì˜ˆ: "ì¢‹ì•„", "ì˜¤ì¼€ì´", "ì•Œê² ì–´", "ì", "ê·¸ëŸ¼", "ì„¤ëª…í•´ì¤„ê²Œ").
- ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™”ì²´ë¡œ 3~6ë¬¸ì¥, ë¬¸ì¥ì€ ì§§ê²Œ.
- ëª©ë¡/ë²ˆí˜¸/ë§ˆí¬ë‹¤ìš´(#, ##, 1., - ë“±) ê¸ˆì§€.
- ì–´ë ¤ìš´ ìš©ì–´ëŠ” ì‰¬ìš´ ë§ë¡œ ë°”ë¡œ í’€ì–´ì¤˜.
- 4~7ë¬¸ì¥: í•µì‹¬ ìš”ì§€ â†’ ì‰¬ìš´ ì˜ˆì‹œ 1ê°œ â†’ ë§ˆì§€ë§‰ì— ì´í•´ í™•ì¸ ì§ˆë¬¸ 1ë¬¸ì¥.
- ë§ˆì§€ë§‰ ì§ˆë¬¸ì„ í•  ë•Œ, "í€´ì¦ˆ:" ë‚˜ "ì§ˆë¬¸:" ì´ë¼ê³  í•˜ì§€ë§ê³ , "ì´ì œ ì§ˆë¬¸ì„ í• ê²Œ" í˜•ì‹ì„ ì‚¬ìš©í•´ì¤˜.
    ex) "í€´ì¦ˆ: ë°ì´í„° ì¤‘ë³µ ì œê±°ë¥¼ ì£¼ë¡œ ë‹´ë‹¹í•˜ëŠ” ë‹¨ê³„ëŠ” ì–´ë””ì¼ê¹Œ?" âŒ,
    ex) "ì´ì œ í€´ì¦ˆ í•˜ë‚˜ ë‚´ë³¼ê²Œ. ë°ì´í„° ì¤‘ë³µ ì œê±°ë¥¼ ì£¼ë¡œ ë‹´ë‹¹í•˜ëŠ” ë‹¨ê³„ëŠ” ì–´ë””ì¼ê¹Œ?" âœ…
- ğŸ”¥ "**í•µì‹¬**:" ê°™ì€ ê°•ì¡°í•˜ëŠ” ê°•ì¡°í•˜ëŠ” ë©˜íŠ¸ë¥¼ ì‚¬ìš©í•˜ì§€ë§ˆ.
    (ì˜ˆ:"**ì¤‘ìš”**: ê¸°íƒ€.." âŒ,
        "**ê°•ì¡°**: ê¸°íƒ€.." âŒ,
         "**ì†Œí”„íŠ¸ì›¨ì–´ ë¹„ìœ **: ê°œë… ìŠ¤í‚¤ë§ˆëŠ” í”„ë¡œê·¸ë¨ì˜ ì „ì²´ ì•„í‚¤í…ì²˜ ë‹¤ì´ì–´ê·¸ë¨ì…ë‹ˆë‹¤." âŒ,
         "ì†Œí”„íŠ¸ì›¨ì–´ ë¹„ìœ ë¥¼ í•´ë³¼ê²Œìš”. ê°œë… ìŠ¤í‚¤ë§ˆëŠ” í”„ë¡œê·¸ë¨ì˜ ì „ì²´ ì•„í‚¤í…ì²˜ ë‹¤ì´ì–´ê·¸ë¨ì…ë‹ˆë‹¤." âœ…
         )
- "**ë¬¸ì¥**"ë¡œ ê°•ì¡°í•˜ëŠ” ë©˜íŠ¸ ì‚¬ìš©í•˜ì§€ë§ˆ.
ê°•ì˜ ë³¸ë¬¸ ì¶œë ¥ì´ ëë‚˜ë©´ ë°˜ë“œì‹œ ì•„ë˜ í˜•ì‹ì˜ ìµœì¢… ê²€í† ë¥¼ ë§ë¶™ì—¬:
###[ìµœì¢… ê²€í† ]
1. [ëª¨ë²” ë‹µì•ˆ ì˜ˆì‹œ]ì™€ ë¹„êµí•´ ì ì ˆí–ˆëŠ”ì§€ ê²€í† 
2. ì¶œì²˜ê°€ ì—…ë¡œë“œí•œ pdfíŒŒì¼ì˜ ë°ì´í„°ì¸ì§€ ê²€í†   
   (ì˜ˆ: "ìë£Œ p12ì— ë”°ë¥´ë©´, ë°ì´í„° ë² ì´ìŠ¤ì˜ ì¥ì ì€ ë°ì´í„°ì˜ ì¼ê´€ì„± ìœ ì§€ì™€ ë°ì´í„°ì˜ ë¬´ê²°ì„± ìœ ì§€ê°€ ìˆì–´." âœ…,  
        "ë°ì´í„°ë² ì´ìŠ¤ì˜ ì¥ì ì€ í‘œì¤€í™”ì•¼." âŒ)

- ì•„ë˜ ë¬¸ì„œ ë‚´ìš©ì— ê·¼ê±°í•´ì„œë§Œ ë‹µí•´. ì—†ìœ¼ë©´ "ìë£Œì—” ì´ ë‚´ìš©ì´ ì—†ì–´"ë¼ê³  ë§í•˜ê³ , ëŒ€ì‹  í•œ ì¤„ ì œì•ˆ.

ë¬¸ì„œ ë‚´ìš©:
{{context}}
ìœ„ì— ì¶œë ¥ ê·œì¹™ì„ ìµœìš°ì„ ìœ¼ë¡œ í•´ì•¼ í•´.
"""
    return ChatPromptTemplate.from_messages([
        ("system", qa_system_template),
        ("human", "{question}"),
    ])


def build_lecture_prompt(P: Dict[str, str]) -> ChatPromptTemplate:
    lecture_system_template = f"""
ë„ˆëŠ” {P['sex']} í™”ìì˜, **{P['display']}** ìŠ¤íƒ€ì¼ AI íŠœí„°ì•¼.
ì•„ë˜ì˜ í˜ë¥´ì†Œë‚˜ ì§€ì¹¨ì„ ë°˜ë“œì‹œ ë”°ë¥¸ë‹¤:
{P['persona_rules']}

ì¶œë ¥ ê·œì¹™(ë°˜ë“œì‹œ ì¤€ìˆ˜):
- ì¸ì‚¬/ìˆ˜ë½/ê°íƒ„/ì „í™˜ ë©˜íŠ¸ë¡œ ì‹œì‘ ê¸ˆì§€(ì˜ˆ: "ì¢‹ì•„", "ì˜¤ì¼€ì´", "ì•Œê² ì–´", "ì", "ê·¸ëŸ¼", "ì„¤ëª…í•´ì¤„ê²Œ").
- ê³§ë°”ë¡œ ë‚´ìš©ìœ¼ë¡œ ì‹œì‘. ì²« ë¬¸ì¥ì€ ì£¼ì œ/í•µì‹¬ ê°œë…ìœ¼ë¡œ.
- ì§€ê¸ˆì€ p{{page_num}} ë‚´ìš©ë§Œ ì‚¬ìš©. ì•ë’¤ í˜ì´ì§€ ì‚¬ì „ ì–¸ê¸‰ ê¸ˆì§€.
- 4~7ë¬¸ì¥: í•µì‹¬ ìš”ì§€ â†’ ì‰¬ìš´ ì˜ˆì‹œ 1ê°œ â†’ ë§ˆì§€ë§‰ì— ì´í•´ í™•ì¸ ì§ˆë¬¸ 1ë¬¸ì¥.
- ë§ˆì§€ë§‰ ì§ˆë¬¸ì„ í•  ë•Œ, "í€´ì¦ˆ:" ë‚˜ "ì§ˆë¬¸:" ì´ë¼ê³  í•˜ì§€ë§ê³ , "ì´ì œ ì§ˆë¬¸ì„ í• ê²Œ" í˜•ì‹ì„ ì‚¬ìš©í•´ì¤˜.
    ex) "í€´ì¦ˆ: ë°ì´í„° ì¤‘ë³µ ì œê±°ë¥¼ ì£¼ë¡œ ë‹´ë‹¹í•˜ëŠ” ë‹¨ê³„ëŠ” ì–´ë””ì¼ê¹Œ?" âŒ,
    ex) "ì´ì œ í€´ì¦ˆ í•˜ë‚˜ ë‚´ë³¼ê²Œ. ë°ì´í„° ì¤‘ë³µ ì œê±°ë¥¼ ì£¼ë¡œ ë‹´ë‹¹í•˜ëŠ” ë‹¨ê³„ëŠ” ì–´ë””ì¼ê¹Œ?" âœ…
- ëª©ë¡/ë²ˆí˜¸/ë§ˆí¬ë‹¤ìš´ ê¸ˆì§€. ì–´ë ¤ìš´ ìš©ì–´ëŠ” ë°”ë¡œ í’€ì–´ì„œ.
- ğŸ”¥ "**í•µì‹¬**:" ê°™ì€ ê°•ì¡°í•˜ëŠ” ê°•ì¡°í•˜ëŠ” ë©˜íŠ¸ë¥¼ ì‚¬ìš©í•˜ì§€ë§ˆ.
    (ì˜ˆ:"**ì¤‘ìš”**: ê¸°íƒ€.." âŒ,
        "**ê°•ì¡°**: ê¸°íƒ€.." âŒ,
         "**ì†Œí”„íŠ¸ì›¨ì–´ ë¹„ìœ **: ê°œë… ìŠ¤í‚¤ë§ˆëŠ” í”„ë¡œê·¸ë¨ì˜ ì „ì²´ ì•„í‚¤í…ì²˜ ë‹¤ì´ì–´ê·¸ë¨ì…ë‹ˆë‹¤." âŒ,
         "ì†Œí”„íŠ¸ì›¨ì–´ ë¹„ìœ ë¥¼ í•´ë³¼ê²Œìš”. ê°œë… ìŠ¤í‚¤ë§ˆëŠ” í”„ë¡œê·¸ë¨ì˜ ì „ì²´ ì•„í‚¤í…ì²˜ ë‹¤ì´ì–´ê·¸ë¨ì…ë‹ˆë‹¤." âœ…
         )
- **ë¡œ ê°•ì¡°í•˜ëŠ” ë©˜íŠ¸ ì‚¬ìš©í•˜ì§€ë§ˆ.

ê°•ì˜ ë³¸ë¬¸ ì¶œë ¥ì´ ëë‚˜ë©´ ë°˜ë“œì‹œ ì•„ë˜ í˜•ì‹ì˜ ìµœì¢… ê²€í† ë¥¼ ë§ë¶™ì—¬:
###[ìµœì¢… ê²€í† ]
1. [ëª¨ë²” ë‹µì•ˆ ì˜ˆì‹œ]ì™€ ë¹„êµí•´ ì ì ˆí–ˆëŠ”ì§€ ê²€í† 
2. ì¶œì²˜ê°€ ì—…ë¡œë“œí•œ pdfíŒŒì¼ì˜ ë°ì´í„°ì¸ì§€ ê²€í†   
   (ì˜ˆ: "ìë£Œ p12ì— ë”°ë¥´ë©´, ë°ì´í„° ë² ì´ìŠ¤ì˜ ì¥ì ì€ ë°ì´í„°ì˜ ì¼ê´€ì„± ìœ ì§€ì™€ ë°ì´í„°ì˜ ë¬´ê²°ì„± ìœ ì§€ê°€ ìˆì–´." âœ…,  
        "ë°ì´í„°ë² ì´ìŠ¤ì˜ ì¥ì ì€ í‘œì¤€í™”ì•¼." âŒ)

í˜„ì¬ í˜ì´ì§€ í…ìŠ¤íŠ¸:
{{context}}
ìœ„ì— ì¶œë ¥ ê·œì¹™ì„ ìµœìš°ì„ ìœ¼ë¡œ í•´ì•¼ í•´.
"""
    return ChatPromptTemplate.from_messages([
        ("system", lecture_system_template),
        ("human", "ê°•ì˜ ë³¸ë¬¸ë§Œ ì¶œë ¥."),
    ])


# =========================
# 7) CSR & TTS (í”„ë¦¬ë¯¸ì—„, ë¶„í• )
# =========================
def recognize_csr(audio_path: str) -> str:
    CSR_URL = "https://naveropenapi.apigw.ntruss.com/recog/v1/stt?lang=Kor"
    if not (NCP_KEY_ID and NCP_KEY):
        return ""
    headers = {
        "X-NCP-APIGW-API-KEY-ID": NCP_KEY_ID,
        "X-NCP-APIGW-API-KEY": NCP_KEY,
        "Content-Type": "application/octet-stream",
    }
    with open(audio_path, "rb") as f:
        data = f.read()
    resp = requests.post(CSR_URL, headers=headers, data=data, timeout=60)
    if resp.status_code != 200:
        return ""
    try:
        return resp.json().get("text", "") or ""
    except Exception:
        return resp.text.strip()

def split_for_tts(text: str, max_len: int = 2800) -> List[str]:
    if len(text) <= max_len:
        return [text]
    parts, cur = [], []
    cur_len = 0
    for sent in re.split(r'(?<=[.?!â€¦]|[ê°€-í£]\))\s+', text):
        if cur_len + len(sent) + 1 > max_len and cur:
            parts.append(" ".join(cur))
            cur, cur_len = [], 0
        cur.append(sent)
        cur_len += len(sent) + 1
    if cur:
        parts.append(" ".join(cur))
    return parts

def synthesize_clova_voice_premium_mp3(
    text: str,
    speaker: str,
    speed: int = 0,
    pitch: int = 0,
    volume: int = 0,
    audio_dir: str = AUDIO_DIR,
) -> List[str]:
    """
    CLOVA Voice Premium TTS (mp3) + 2800ì ë¶„í• . ë‹¤ì¤‘ íŒŒì¼ ê²½ë¡œ ë°˜í™˜.
    """
    if not (NCP_KEY_ID and NCP_KEY):
        return []
    os.makedirs(audio_dir, exist_ok=True)
    headers = {
        "X-NCP-APIGW-API-KEY-ID": NCP_KEY_ID,
        "X-NCP-APIGW-API-KEY": NCP_KEY,
        "Content-Type": "application/x-www-form-urlencoded; charset=utf-8",
    }
    chunks = split_for_tts(text, max_len=2800)
    out_paths = []
    delay = 0.6
    for idx, chunk in enumerate(chunks, start=1):
        data = {
            "speaker": speaker,
            "text": chunk,
            "format": "mp3",
            "speed": str(speed),
            "pitch": str(pitch),
            "volume": str(volume),
        }
        for attempt in range(6):
            resp = requests.post(TTS_PREMIUM_URL, headers=headers, data=data, timeout=60)
            if resp.status_code == 200:
                fname = f"{uuid.uuid4().hex}"
                if len(chunks) == 1:
                    fname = f"{fname}.mp3"
                else:
                    fname = f"{fname}_part{idx}.mp3"
                path = os.path.join(audio_dir, fname)
                with open(path, "wb") as f:
                    f.write(resp.content)
                out_paths.append(path)
                break
            elif resp.status_code in (429, 503):
                time.sleep(delay); delay *= 2
            else:
                raise RuntimeError(f"TTS ì‹¤íŒ¨ {resp.status_code}: {resp.text}")
    return out_paths

# =========================
# 8) Units (í˜ì´ì§€ ë‹¨ì›)
# =========================
UNITS_BY_DOC: Dict[str, List[Dict[str, Any]]] = {}  # doc_id -> units(list)
LECTURE_STATE: Dict[str, int] = {}                  # session_id -> cur index

def build_units_from_documents(documents) -> List[Dict[str, Any]]:
    """í˜ì´ì§€ë³„ í…ìŠ¤íŠ¸ë¥¼ ëª¨ì•„ ë‹¨ì› ìƒì„± (ì²« ë²ˆì§¸ ì½”ë“œ ìŠ¤íƒ€ì¼, 4000ì ì œí•œ)."""
    page_buckets: Dict[int, List[str]] = defaultdict(list)
    for d in documents:
        p = int(d.metadata.get("page", 0))
        page_buckets[p].append(d.page_content)
    units = []
    for p in sorted(page_buckets.keys()):
        text = "\n".join(page_buckets[p]).strip()
        # [FIX] ìŠ¤ìº” PDF ë°©ì§€: ì™„ì „ ë¹ˆ í˜ì´ì§€ëŠ” ìŠ¤í‚µí•˜ì§€ ë§ê³  ì•Œë¦¼ ë¬¸êµ¬ë¡œ ëŒ€ì²´
        if not text:
            text = "(ì´ í˜ì´ì§€ëŠ” ì¶”ì¶œëœ í…ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤. ìŠ¤ìº” PDFì¼ ìˆ˜ ìˆì–´ìš”.)"
        if len(text) > 4000:
            text = text[:4000] + "\n(ì´í•˜ ìƒëµ)"
        units.append({"page0": p, "page": p + 1, "text": text})
    return units

def teach_unit_text(P: Dict[str, str], unit: Dict[str, Any]) -> str:
    prompt = build_lecture_prompt(P)
    msgs = prompt.format_messages(page_num=unit["page"], context=unit["text"])
    resp = llm.invoke(msgs)
    return getattr(resp, "content", str(resp))

# =========================
# 9) RetrievalQA Builder
# =========================
def build_qa_chain(P: Dict[str, str], vectorstore: FAISS) -> RetrievalQA:
    retriever = vectorstore.as_retriever(search_kwargs={"k": 5})
    prompt = build_qa_prompt(P)
    return RetrievalQA.from_chain_type(
        llm=llm,
        chain_type="stuff",
        retriever=retriever,
        return_source_documents=True,
        chain_type_kwargs={
            "prompt": prompt,
            "document_variable_name": "context",   # ì§€ê¸ˆ ì½”ë“œ
            # â†“ ì¶”ê°€
            #"input_key": "query",                  # ì§ˆë¬¸ ì…ë ¥ í•„ë“œ ëª…ì‹œ
            #"output_key": "result",                # ì¶œë ¥ í•„ë“œ ëª…ì‹œ
        },
    )

# =========================
# 10) Schemas
# =========================
class ChatReq(BaseModel):
    session_id: str
    question: str
    doc_id: Optional[str] = "current_doc"
    want_tts: bool = False
    persona: Optional[str] = None
    tts_speed: Optional[int] = None
    tts_volume: Optional[int] = None
    tts_pitch: Optional[int] = None

class ChatResp(BaseModel):
    answer: str
    audio_url: Optional[str] = None
    audio_urls: Optional[List[str]] = None
    # [FIX] ê°€ë³€ ë””í´íŠ¸ ì œê±°
    used_refs: Optional[List[Dict[str, Any]]] = Field(default=None)

# =========================
# 11) Pages
# =========================
@app.get("/", response_class=HTMLResponse)
async def home(request: Request):
    return templates.TemplateResponse(
        "index.html",
        {"request": request, "PERSONAS": PERSONAS}
    )
@app.get("/chat", response_class=HTMLResponse)
async def chat(request: Request, teacher: str):
    teacher_info = PERSONAS.get(teacher)
    if not teacher_info:
        return HTMLResponse(content=f"<h1>ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ê°•ì‚¬: {teacher}</h1>", status_code=404)
    return templates.TemplateResponse(
        "chat.html",
        {"request": request, "teacher": teacher_info, "teacher_key": teacher}
    )

# =========================
# 12) PDF Ingest â†’ FAISS + Units
# =========================
from fastapi import FastAPI, UploadFile, File
from pathlib import Path
import shutil, os
from typing import List
import re
from langchain.schema import Document
import uuid

# ============================
# 1) CLOVA ì„¸ê·¸ë©˜í…Œì´ì…˜ ì‚¬ìš© ì—¬ë¶€
# ============================
USE_CLOVA_SEG = os.getenv("USE_CLOVA_SEGMENTATION", "0") == "1"

# ============================
# 2) CLOVA ì„¸ê·¸ë©˜í…Œì´ì…˜ (Stream API)
# ============================
def segment_text_clova_auto(
    text: str,
    api_key: str = os.getenv("CLOVASTUDIO_API_KEY", ""),
    apigw_key: str = os.getenv("NCP_CLOVA_KEY", ""),
    app_id: str = os.getenv("CLOVASTUDIO_APP_ID", ""),
    stage: str = os.getenv("CLOVASTUDIO_STAGE", "testapp"),
    mode: str = os.getenv("CLOVASTUDIO_SEG_MODE", "auto"),
) -> List[str]:
    """ CLOVA Segmentation API (stream â†’ apigw fallback) """
    url = "https://clovastudio.stream.ntruss.com/v1/api-tools/segmentation"
    headers = {
        "Content-Type": "application/json; charset=utf-8",
        "Authorization": f"Bearer {api_key}",
        "X-NCP-CLOVASTUDIO-REQUEST-ID": str(uuid.uuid4()),
    }
    payload = {"text": text, "postProcess": True}
    try:
        r = requests.post(url, headers=headers, json=payload, timeout=30)
        r.raise_for_status()
        data = r.json()
        segs = data.get("result", {}).get("segments", [])
        return [s.get("text", "").strip() for s in segs if isinstance(s, dict)]
    except Exception as e:
        print(f"[WARN] CLOVA ì„¸ê·¸ë©˜í…Œì´ì…˜ ì‹¤íŒ¨ â†’ ë¡œì»¬ ë¶„í• ë¡œ ëŒ€ì²´: {e}")
        return segment_text_local(text)

# ============================
# 3) ë¡œì»¬ ì„¸ê·¸ë©˜í…Œì´ì…˜
# ============================
def segment_text_local(
    text: str, target_len: int = 600, min_len: int = 250, max_len: int = 1200
) -> List[str]:
    """ ë¬¸ë‹¨ ë‹¨ìœ„ ë¶„í•  + ë¬¸ì¥ ë‹¨ìœ„ ì„¸ë¶„í™” """
    t = re.sub(r"\r\n?", "\n", text)
    paras = [p.strip() for p in re.split(r"\n\s*\n+", t) if p.strip()]

    def split_sents(block: str) -> List[str]:
        return [s.strip() for s in re.split(r'(?<=[.?!â€¦]|[ê°€-í£]\))\s+', block) if s.strip()]

    expanded: List[str] = []
    for p in paras:
        if len(p) <= max_len:
            expanded.append(p)
        else:
            sents = split_sents(p)
            cur, cur_len = [], 0
            for s in sents:
                if cur_len + len(s) + 1 > target_len and cur:
                    expanded.append(" ".join(cur))
                    cur, cur_len = [], 0
                cur.append(s)
                cur_len += len(s) + 1
            if cur:
                expanded.append(" ".join(cur))

    out, cur, cur_len = [], [], 0
    for blk in (expanded or paras):
        if cur_len and cur_len + len(blk) < min_len:
            cur.append(blk)
            cur_len += len(blk) + 1
            continue
        if cur:
            out.append(" ".join(cur))
            cur, cur_len = [], 0
        if len(blk) < min_len:
            cur, cur_len = [blk], len(blk)
        else:
            out.append(blk)
    if cur:
        out.append(" ".join(cur))
    return out

# ============================
# 4) STT (ì„ì‹œ ë²„ì „)
# ============================
import os
import requests
import numpy as np
import soundfile as sf
from pathlib import Path
from typing import List

# === ë¦¬ìƒ˜í”Œë§ / WAV ìœ í‹¸ ===
def _resample_to_16k_mono(audio: np.ndarray, sr: int, target_sr: int = 16000) -> np.ndarray:
    """ê°„ë‹¨í•œ ì„ í˜•ë³´ê°„ ë¦¬ìƒ˜í”Œë§. stereoë©´ mono ë³€í™˜."""
    if audio.ndim > 1:
        audio = audio.mean(axis=1)
    if sr == target_sr:
        return audio.astype(np.float32)
    n_src = len(audio)
    n_tgt = int(round(n_src * target_sr / sr))
    if n_tgt <= 1:
        return audio.astype(np.float32)
    x_old = np.linspace(0.0, 1.0, num=n_src, endpoint=True)
    x_new = np.linspace(0.0, 1.0, num=n_tgt, endpoint=True)
    resampled = np.interp(x_new, x_old, audio.astype(np.float32))
    return resampled.astype(np.float32)

def _write_pcm16_wav(path: str, audio: np.ndarray, sr: int = 16000):
    sf.write(path, audio, sr, subtype="PCM_16")

def _split_wav_by_seconds(src_path: str, chunk_seconds: int = 55) -> List[str]:
    """ê¸¸ë©´ ì´ˆ ë‹¨ìœ„ë¡œ ì˜ë¼ ì—¬ëŸ¬ íŒŒì¼ ê²½ë¡œ ë°˜í™˜."""
    audio, sr = sf.read(src_path, always_2d=False)
    audio = audio if isinstance(audio, np.ndarray) else np.array(audio)
    audio = _resample_to_16k_mono(audio, sr, target_sr=16000)
    frames = len(audio)
    hop = int(chunk_seconds * 16000)
    out_paths: List[str] = []
    base = Path(src_path)
    for i, start in enumerate(range(0, frames, hop)):
        seg = audio[start:start+hop]
        if len(seg) == 0:
            continue
        out_p = str(base.with_name(f"{base.stem}_part{i+1}.wav"))
        _write_pcm16_wav(out_p, seg, 16000)
        out_paths.append(out_p)
    return out_paths

# === CSR ë‹¨ì¼ í˜¸ì¶œ ===
STT_ENDPOINT = "https://naveropenapi.apigw.ntruss.com/recog/v1/stt"

def _stt_call_single_wav(wav_path: str, key_id: str, key_secret: str, lang: str = "Kor") -> str:
    """CSR êµ¬ë²„ì „ APIì— ë‹¨ì¼ WAV(PCM16/16k/mono)ë¥¼ ì „ì†¡í•˜ê³  í…ìŠ¤íŠ¸ ë°˜í™˜."""
    headers = {
        "X-NCP-APIGW-API-KEY-ID": key_id,
        "X-NCP-APIGW-API-KEY": key_secret,
        "Content-Type": "application/octet-stream",
    }
    params = {"lang": lang}  # Kor, Eng, Jpn, Chn
    with open(wav_path, "rb") as f:
        data = f.read()
    resp = requests.post(STT_ENDPOINT, headers=headers, params=params, data=data, timeout=120)
    if resp.status_code != 200:
        raise RuntimeError(f"STT ì‹¤íŒ¨: {resp.status_code} {resp.text}")
    try:
        js = resp.json()
        return js.get("text", "") or resp.text
    except Exception:
        return resp.text

# === CSR ë©€í‹° ì²­í¬ í˜¸ì¶œ ===
def stt_transcribe_wav_to_text(wav_path: str, lang: str = "Kor") -> str:
    """CSR API í˜¸ì¶œí•´ì„œ wav íŒŒì¼ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜ (ë””ë²„ê·¸ ë²„ì „: ì›ë³¸ ì‘ë‹µ ì¶œë ¥)"""
    NCP_KEY_ID = os.getenv("NCP_CLOVA_KEY_ID")
    NCP_KEY = os.getenv("NCP_CLOVA_KEY")

    if not (NCP_KEY_ID and NCP_KEY):
        raise RuntimeError("â— NCP_CLOVA_KEY_ID / NCP_CLOVA_KEY í™˜ê²½ë³€ìˆ˜ê°€ í•„ìš”í•©ë‹ˆë‹¤")

    parts = _split_wav_by_seconds(wav_path, chunk_seconds=55)
    if not parts:
        audio, sr = sf.read(wav_path, always_2d=False)
        audio = _resample_to_16k_mono(np.array(audio), sr, target_sr=16000)
        tmp = str(Path(wav_path).with_name(f"{Path(wav_path).stem}_16k.wav"))
        _write_pcm16_wav(tmp, audio, 16000)
        parts = [tmp]

    texts: List[str] = []
    for i, p in enumerate(parts, 1):
        try:
            print(f"[STT] part {i}/{len(parts)}: {Path(p).name}")
            headers = {
                "X-NCP-APIGW-API-KEY-ID": NCP_KEY_ID,
                "X-NCP-APIGW-API-KEY": NCP_KEY,
                "Content-Type": "application/octet-stream",
            }
            params = {"lang": lang}
            with open(p, "rb") as f:
                resp = requests.post(STT_ENDPOINT, headers=headers, params=params, data=f.read(), timeout=120)

            print(f"[DEBUG] CSR ì‘ë‹µ ì›ë¬¸ (status {resp.status_code}): {resp.text}")

            if resp.status_code != 200:
                continue

            try:
                data = resp.json()
            except Exception as e:
                print("[WARN] JSON íŒŒì‹± ì‹¤íŒ¨:", e)
                continue

            text = data.get("text", "").strip()
            if not text and "result" in data:
                text = " ".join([seg.get("text","") for seg in data["result"]]).strip()

            if text:
                texts.append(text)

        except Exception as e:
            print(f"[WARN] STT part {i} ì˜¤ë¥˜: {e}")

    full = " ".join([t for t in texts if t])
    print(f"[INFO] STT ì „ì²´ ë³€í™˜ ê²°ê³¼ ê¸¸ì´: {len(full)}ì")
    return full.strip()


# === TXT ì²˜ë¦¬ ===
def load_txt_as_documents(txt_path: str) -> List[Document]:
    text = Path(txt_path).read_text(encoding="utf-8", errors="ignore")
    # CLOVA ì„¸ê·¸ë©˜í…Œì´ì…˜ ì‚¬ìš© ì—¬ë¶€
    if USE_CLOVA_SEG:
        try:
            segments = segment_text_clova_auto(
                text,
                api_key=api_key,
                apigw_key=NCP_KEY,
                app_id=CLOVA_APP_ID,
                stage=CLOVA_STAGE,
                mode=os.getenv("CLOVASTUDIO_SEG_MODE", "auto"),
            )
        except Exception as e:
            print(f"[WARN] ì„¸ê·¸ë©˜í…Œì´ì…˜ ì‹¤íŒ¨ â†’ ë¡œì»¬ ë¶„í• ë¡œ ëŒ€ì²´: {e}")
            segments = segment_text_local(text)
    else:
        segments = segment_text_local(text)

    docs: List[Document] = []
    for i, seg in enumerate(segments):
        docs.append(
            Document(page_content=seg, metadata={"source": Path(txt_path).name, "page": i})
        )
    return docs

# === WAV ì²˜ë¦¬ (STT â†’ ì„¸ê·¸ë©˜í…Œì´ì…˜) ===
CSR_LANG = os.getenv("CSR_LANG", "Kor")  # í•œêµ­ì–´ ê¸°ë³¸ê°’
def load_wav_as_documents(wav_path: str) -> List[Document]:
    print(f"[INFO] WAV ì—…ë¡œë“œ: {wav_path}")
    transcript = stt_transcribe_wav_to_text(wav_path, lang=CSR_LANG)
    if not transcript:
        raise RuntimeError("STT ê²°ê³¼ê°€ ë¹„ì—ˆìŠµë‹ˆë‹¤.")

    if USE_CLOVA_SEG:
        try:
            segments = segment_text_clova_auto(
                transcript,
                api_key=api_key,
                apigw_key=NCP_KEY,
                app_id=CLOVA_APP_ID,
                stage=CLOVA_STAGE,
                mode=os.getenv("CLOVASTUDIO_SEG_MODE", "auto"),
            )
        except Exception as e:
            print(f"[WARN] ì„¸ê·¸ë©˜í…Œì´ì…˜ ì‹¤íŒ¨ â†’ ë¡œì»¬ ë¶„í• ë¡œ ëŒ€ì²´: {e}")
            segments = segment_text_local(transcript)
    else:
        segments = segment_text_local(transcript)

    docs: List[Document] = []
    for i, seg in enumerate(segments):
        docs.append(
            Document(page_content=seg, metadata={"source": Path(wav_path).name, "page": i})
        )
    return docs

# === ì²­í¬ ë¶„í•  ===
def build_chunks_from_documents(
    documents: List[Document],
    min_chars: int = 5,
    chunk_size: int = 400,
    chunk_overlap: int = 80,
) -> List[Document]:
    splitter = RecursiveCharacterTextSplitter(
        chunk_size=chunk_size,
        chunk_overlap=chunk_overlap,
        separators=["\n\n", "\n", " ", ""],
    )

    chunks = [
        d for d in splitter.split_documents(documents)
        if len(d.page_content.strip()) >= min_chars
    ]

    if not chunks:
        chunks = [
            Document(page_content=d.page_content.strip(), metadata=d.metadata)
            for d in documents
            if len(d.page_content.strip()) >= min_chars
        ]

    if not chunks:
        merged = "\n".join(d.page_content for d in documents).strip()
        if merged:
            src = documents[0].metadata.get("source", "input")
            chunks = [Document(page_content=merged, metadata={"source": src, "page": 0})]
        else:
            raise ValueError("ì…ë ¥ í…ìŠ¤íŠ¸ê°€ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤.")

    return chunks
@app.post("/ingest")
async def ingest_api(file: UploadFile = File(...)):
    file_path = os.path.join(UPLOAD_DIR, file.filename)
    with open(file_path, "wb") as f:
        f.write(await file.read())

    ext = Path(file.filename).suffix.lower()
    if ext == ".pdf":
        loader = PyPDFLoader(file_path)
        documents = loader.load()
    elif ext == ".txt":
        documents = load_txt_as_documents(file_path)
    elif ext == ".wav":
        documents = load_wav_as_documents(file_path)
    else:
        return {"error": f"ì§€ì›í•˜ì§€ ì•ŠëŠ” í™•ì¥ì: {ext}"}

    chunks = build_chunks_from_documents(documents, chunk_size=400, chunk_overlap=80)

    doc_id = "current_doc"  # ì„¸ì…˜ë§ˆë‹¤ ë‹¤ë¥´ê²Œ í•˜ê³  ì‹¶ìœ¼ë©´ uuid ë¶™ì´ê¸°
    shutil.rmtree(_vs_path(doc_id), ignore_errors=True)
    os.makedirs(_vs_path(doc_id), exist_ok=True)

    sample_text = chunks[0].page_content[:200]
    sample_vector = embeddings.embed_query(sample_text)

    vs = FAISS.from_documents(chunks, embedding=embeddings)
    persist_faiss(vs, doc_id)

    UNITS_BY_DOC[doc_id] = build_units_from_documents(documents)

    return {
        "doc_id": doc_id,
        "ext": ext,
        "pages": len(documents),
        "chunks": len(chunks),
        "sample_text": sample_text,
        "sample_vector_dim": len(sample_vector),
        "message": f"{ext.upper()} ì—…ë¡œë“œ ë° ë²¡í„° ì €ì¥ ì™„ë£Œ"
    }



# =========================
# 13) Chat (ëª…ë ¹ì–´/ê°•ì˜/RAG â†’ TTS)
# =========================
def _pick_persona(req_persona: Optional[str]) -> Dict[str, str]:
    key = (req_persona or DEFAULT_PERSONA_KEY).strip()
    return PERSONAS.get(key, P_DEFAULT)

def _tts_paths_to_urls(paths: List[str]) -> Tuple[Optional[str], Optional[List[str]]]:
    if not paths:
        return None, None
    urls = [f"/audio/{os.path.basename(p)}" for p in paths]
    return urls[0], urls

@app.post("/chat", response_model=ChatResp)
async def chat_api(req: ChatReq):
    db = SessionLocal()
    doc_id = req.doc_id or "current_doc"
    P = _pick_persona(req.persona)

    # ë²¡í„°ìŠ¤í† ì–´ ë¡œë“œ
    try:
        vectorstore = load_faiss(doc_id)
    except Exception:
        db.close()  # [FIX] ëˆ„ìˆ˜ ë°©ì§€
        return {"answer": "â— í•´ë‹¹ ë¬¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € PDFë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš”.", "used_refs": []}

    # user log
    save_interaction(db, session_id=req.session_id, role="user",
                     content=req.question, doc_id=doc_id)

    raw = req.question.strip()
    audio_url, audio_urls, audio_path = None, None, None

    # ===== ê°•ì˜ ëª…ë ¹ì–´ ì²˜ë¦¬ =====
    if raw in ("/teach", "/next", "/prev") or raw.startswith("/goto"):
        units = UNITS_BY_DOC.get(doc_id)
        if not units:
            try:
                metas = SessionLocal().query(DocumentMeta).filter_by(doc_id=doc_id).first()
                filename = metas.filename if metas else None
                if filename:
                    loader = PyPDFLoader(os.path.join(UPLOAD_DIR, filename))
                    documents = loader.load()
                    UNITS_BY_DOC[doc_id] = build_units_from_documents(documents)
                    units = UNITS_BY_DOC[doc_id]
            except Exception:
                pass
        if not units:
            db.close()
            return {"answer": "ê°•ì˜ ë‹¨ì›ì´ ì¤€ë¹„ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤. PDFë¥¼ ë‹¤ì‹œ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.", "used_refs": []}

        cur = LECTURE_STATE.get(req.session_id, 0)

        if raw == "/prev":
            cur = max(0, cur - 1)
        elif raw == "/next":
            if cur < len(units) - 1:
                cur += 1
        elif raw.startswith("/goto"):
            m = re.search(r"/goto\s+(\d+)", raw)
            if m:
                page_target = int(m.group(1))
                idx = None
                for i, u in enumerate(units):
                    if u["page"] == page_target:
                        idx = i
                        break
                if idx is None:
                    if page_target <= units[0]["page"]:
                        idx = 0
                    elif page_target >= units[-1]["page"]:
                        idx = len(units) - 1
                    else:
                        idx = min(range(len(units)), key=lambda i: abs(units[i]["page"] - page_target))
                cur = idx

        LECTURE_STATE[req.session_id] = cur
        unit = units[cur]

        answer = teach_unit_text(P, unit)
        used_refs = [{"type": "page", "page": unit["page"]}]

        if req.want_tts:
            speed = req.tts_speed if req.tts_speed is not None else 0
            volume = req.tts_volume if req.tts_volume is not None else 0
            pitch = req.tts_pitch if req.tts_pitch is not None else 0
            paths = synthesize_clova_voice_premium_mp3(
                answer, speaker=P["speaker"], speed=speed, pitch=pitch, volume=volume
            )
            audio_url, audio_urls = _tts_paths_to_urls(paths)
            audio_path = paths[0] if paths else None
        else:
            audio_url, audio_urls, audio_path = None, None, None

        save_interaction(
            db,
            session_id=req.session_id,
            role="assistant",
            content=answer,
            doc_id=doc_id,
            refs={"mode": "lecture", "page": unit["page"]},
            audio_path=audio_path,
        )
        db.close()
        return ChatResp(answer=answer, audio_url=audio_url, audio_urls=audio_urls, used_refs=used_refs)

    # ===== Q&A (RetrievalQA) =====
    try:
        chain = build_qa_chain(P, vectorstore)
        docs = vectorstore.similarity_search(raw, k=3)
        if not docs:  # ê´€ë ¨ ë¬¸ì„œê°€ ì•„ì˜ˆ ì—†ìœ¼ë©´
            db.close()
            return ChatResp(
                answer="â— ì—…ë¡œë“œí•œ ìë£Œ ì•ˆì— ì´ ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤.",
                used_refs=[]
            )
        res = chain({"query": raw})

        # [FIX] LangChain ë²„ì „ í˜¸í™˜: result / output_text / answer ëª¨ë‘ ëŒ€ì‘
        answer = (
            (res.get("result") or res.get("output_text") or res.get("answer") or "")
        ).strip()
        if not answer:
            answer = "ìë£Œì—” ì´ ë‚´ìš©ì´ ì—†ì–´. ëŒ€ì‹  ê´€ë ¨ í‚¤ì›Œë“œë¥¼ ë°”ê¿”ì„œ ë‹¤ì‹œ ë¬¼ì–´ë³´ëŠ” ê±´ ì–´ë•Œìš”?"

        srcs = res.get("source_documents", []) or []

        used_refs: List[Dict[str, Any]] = []
        for d in srcs:
            try:
                p0 = int(d.metadata.get("page", 0))
            except Exception:
                p0 = 0
            preview = (d.page_content or "").strip().replace("\n", " ")
            if len(preview) > 160:
                preview = preview[:160] + "â€¦"
            used_refs.append({"type": "source", "page": p0 + 1, "preview": preview})

        # ì¤‘ë³µ í˜ì´ì§€ ì œê±°
        seen = set()
        deduped = []
        for r in used_refs:
            key = (r["type"], r["page"])
            if key not in seen:
                deduped.append(r); seen.add(key)
        used_refs = deduped[:5]

        if req.want_tts:
            speed = req.tts_speed if req.tts_speed is not None else 0
            volume = req.tts_volume if req.tts_volume is not None else 0
            pitch = req.tts_pitch if req.tts_pitch is not None else 0
            paths = synthesize_clova_voice_premium_mp3(
                answer, speaker=P["speaker"], speed=speed, pitch=pitch, volume=volume
            )
            audio_url, audio_urls = _tts_paths_to_urls(paths)
            audio_path = paths[0] if paths else None
        else:
            audio_url, audio_urls, audio_path = None, None, None

        save_interaction(
            db,
            session_id=req.session_id,
            role="assistant",
            content=answer,
            doc_id=doc_id,
            refs={"mode": "qa", "used_refs": used_refs},
            audio_path=audio_path,
        )
        db.close()
        return ChatResp(answer=answer, audio_url=audio_url, audio_urls=audio_urls, used_refs=used_refs)

    except Exception as e:
        err_msg = f"ë‹µë³€ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}"
        save_interaction(db, session_id=req.session_id, role="assistant", content=err_msg, doc_id=doc_id)
        db.close()
        return ChatResp(answer=err_msg, used_refs=[])

# =========================
# 14) Audio Static Serving
# =========================
@app.get("/audio/{filename}")
async def get_audio(filename: str):
    from fastapi import HTTPException
    path = os.path.join(AUDIO_DIR, filename)
    if not os.path.isfile(path):
        raise HTTPException(status_code=404, detail="Audio not found")
    return FileResponse(path, media_type="audio/mpeg", filename=filename)

# =========================
# 15) Lecture Helpers
# =========================
@app.post("/lecture/reset")
async def lecture_reset(session_id: str):
    LECTURE_STATE.pop(session_id, None)
    return {"message": "ok", "session_id": session_id, "state": "reset"}

@app.get("/lecture/status")
async def lecture_status(session_id: str):
    cur = LECTURE_STATE.get(session_id, 0)
    return {"session_id": session_id, "current_index": cur}

# =========================
# 16) Persona Helpers
# =========================
@app.get("/personas")
async def list_personas():
    out = []
    for k, v in PERSONAS.items():
        out.append({"key": k, "display": v["display"], "sex": v["sex"], "speaker": v["speaker"]})
    return {"personas": out}

# =========================
# 17) Local run (optional)
# =========================
if __name__ == "__main__":
    import uvicorn
    uvicorn.run("app:app", host="0.0.0.0", port=8000, reload=True)
